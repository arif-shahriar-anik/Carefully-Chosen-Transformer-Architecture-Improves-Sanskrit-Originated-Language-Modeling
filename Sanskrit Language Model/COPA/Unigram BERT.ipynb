{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209e3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6ecfa560884c9a31\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-6ecfa560884c9a31/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\copa-translated\\\\hi\\\\train.jsonl\", \\\n",
    "                             split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1cb0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d361c8987e918d36\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-d361c8987e918d36/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "val_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\copa-translated\\\\hi\\\\val.jsonl\", \\\n",
    "                            split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25a14c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-07180908d3559f11\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-07180908d3559f11/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\copa-translated\\\\hi\\\\test.jsonl\", \\\n",
    "                             split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99241519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "datasets = DatasetDict()\n",
    "datasets['train'] = train_dataset\n",
    "datasets['validation'] = val_dataset\n",
    "datasets['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# datasets = load_dataset(\"indic_glue\",\"copa.hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a82927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label'],\n",
       "        num_rows: 362\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label'],\n",
       "        num_rows: 88\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label'],\n",
       "        num_rows: 449\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac25dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': ['मेरे शरीर ने घास पर छाया डाली।',\n",
       "  'महिला ने अपने दोस्त के कठिन व्यवहार को सहन किया।',\n",
       "  'महिलाएं कॉफी के लिए मिलीं।',\n",
       "  'धावक ने शॉर्ट्स पहनी थी।',\n",
       "  'पार्टी के मेहमान सोफे के पीछे छिप गए।'],\n",
       " 'choice1': ['सूरज उग रहा था।',\n",
       "  'महिला को पता था कि उसका दोस्त कठिन समय से गुजर रहा है।',\n",
       "  'एक नए स्थान में कैफे फिर से खुल गया।',\n",
       "  'पूर्वानुमान में उच्च तापमान की भविष्यवाणी की गई थी।',\n",
       "  'यह एक सरप्राइज पार्टी थी।'],\n",
       " 'choice2': ['घास काटी गई।',\n",
       "  'महिला को लगा कि उसके दोस्त ने उसकी दया का फायदा उठाया।',\n",
       "  'वे एक-दूसरे को पकड़ना चाहते थे।',\n",
       "  'उसने समुद्र तट के साथ दौड़ने की योजना बनाई।',\n",
       "  'यह जन्मदिन की पार्टी थी।'],\n",
       " 'question': ['cause', 'cause', 'cause', 'cause', 'cause'],\n",
       " 'idx': [0, 1, 2, 3, 4],\n",
       " 'label': [0, 0, 1, 0, 0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a882b123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': ['आइटम को बबल रैप में पैक किया गया था।',\n",
       "  'मैंने अपनी जेबें खाली कर दीं।'],\n",
       " 'choice1': ['यह नाजुक था।', 'मैंने एक टिकट स्टब को पुनः प्राप्त किया।'],\n",
       " 'choice2': ['छोटा था।', 'मुझे एक हथियार मिला।'],\n",
       " 'question': ['cause', 'effect'],\n",
       " 'idx': [0, 1],\n",
       " 'label': [0, 0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40831c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce2da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = datasets[\"train\"][\"label\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1afd418e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    186\n",
       "0    176\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33520fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0161e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8fc03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_names = ['choice1', 'choice2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6010dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    premise = [[context] * 2 for context in examples[\"premise\"]]\n",
    "    cause = [[f\"{examples[choice][i]}\" for choice in choice_names] for i,_ in enumerate(premise)]\n",
    "\n",
    "    premise = sum(premise, [])\n",
    "    cause = sum(cause, [])\n",
    "    \n",
    "#     print(premise)\n",
    "#     print(cause)\n",
    "    \n",
    "\n",
    "    tokenized_examples = tokenizer(premise, cause, truncation=True)\n",
    "#     print(len(tokenized_examples))\n",
    "    return {k: [v[i : i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}\n",
    "    #return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29d4330d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[[2,\n",
       "    198,\n",
       "    437,\n",
       "    18,\n",
       "    4279,\n",
       "    17,\n",
       "    3065,\n",
       "    2989,\n",
       "    6,\n",
       "    3,\n",
       "    2196,\n",
       "    7215,\n",
       "    44,\n",
       "    32,\n",
       "    6,\n",
       "    3],\n",
       "   [2, 198, 437, 18, 4279, 17, 3065, 2989, 6, 3, 4279, 14, 998, 51, 6, 3]]],\n",
       " 'token_type_ids': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]],\n",
       " 'attention_mask': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = preprocess_function(datasets[\"train\"][:1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82eb26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': ['मेरे शरीर ने घास पर छाया डाली।'],\n",
       " 'choice1': ['सूरज उग रहा था।'],\n",
       " 'choice2': ['घास काटी गई।'],\n",
       " 'question': ['cause'],\n",
       " 'idx': [0],\n",
       " 'label': [0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1feaf793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] मेरे शरीर ने घास पर छाया डाली।[SEP] सूरज उग रहा था।[SEP]\n",
      "[CLS] मेरे शरीर ने घास पर छाया डाली।[SEP] घास काटी गई।[SEP]\n"
     ]
    }
   ],
   "source": [
    "for chunk in temp['input_ids'][0]:\n",
    "    print(tokenizer.decode(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74a9a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-6ecfa560884c9a31\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-7531a70bbfe3f227.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-d361c8987e918d36\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-47c8669770eff831.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-07180908d3559f11\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-d380784b72a98393.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06f0df9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'मेरे शरीर ने घास पर छाया डाली।',\n",
       " 'choice1': 'सूरज उग रहा था।',\n",
       " 'choice2': 'घास काटी गई।',\n",
       " 'question': 'cause',\n",
       " 'idx': 0,\n",
       " 'label': 0,\n",
       " 'input_ids': [[2,\n",
       "   198,\n",
       "   437,\n",
       "   18,\n",
       "   4279,\n",
       "   17,\n",
       "   3065,\n",
       "   2989,\n",
       "   6,\n",
       "   3,\n",
       "   2196,\n",
       "   7215,\n",
       "   44,\n",
       "   32,\n",
       "   6,\n",
       "   3],\n",
       "  [2, 198, 437, 18, 4279, 17, 3065, 2989, 6, 3, 4279, 14, 998, 51, 6, 3]],\n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed82f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        \n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f66e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "839637aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 362\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b86280a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 362\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = tokenized_datasets[\"train\"].remove_columns(['premise', 'choice1', 'choice2', 'question', 'idx'])\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18137ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "samples = [temp_data[i] for i in range(1)]\n",
    "temp = data_collator(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d4ebba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581e6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = tokenized_datasets.remove_columns(['premise','choice1','choice2','question','idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65cb9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab6c0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a041fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a51ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fb04668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94a90bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_data = tokenized_datasets.remove_columns(['premise','choice1','choice2','question','idx'])\n",
    "# temp = [temp_data[\"train\"][i]for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "810071c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = data_collator(temp)\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "651ca140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in batch[\"input_ids\"].tolist():\n",
    "#     for choice in sample:\n",
    "#         print(tokenizer.decode(choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bac1fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb0137c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "056872a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_swag_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    #learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    #num_train_epochs=2,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.04,\n",
    "    fp16=True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    #eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88e79967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6870505213737488,\n",
       " 'eval_accuracy': 0.48863636363636365,\n",
       " 'eval_runtime': 3.5989,\n",
       " 'eval_samples_per_second': 24.452,\n",
       " 'eval_steps_per_second': 0.834}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bbbae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673665</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670344</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24, training_loss=0.669298013051351, metrics={'train_runtime': 6.66, 'train_samples_per_second': 108.709, 'train_steps_per_second': 3.604, 'total_flos': 21011695779408.0, 'train_loss': 0.669298013051351, 'epoch': 2.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41bd5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eabd6736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6808228492736816,\n",
       " 'eval_accuracy': 0.6080178173719376,\n",
       " 'eval_runtime': 0.6799,\n",
       " 'eval_samples_per_second': 660.389,\n",
       " 'eval_steps_per_second': 22.062,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a7be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_true, _ = trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b2d9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(y_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4b6ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['choice1', 'choice2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3323f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion matrix for COPA')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#plot heatmap of confusion matrix\n",
    "mat = confusion_matrix(y_true, y_preds)\n",
    "heatmap(mat, cmap=\"Pastel1_r\", fmt=\"d\", xticklabels=target_names, yticklabels=target_names, annot=True)\n",
    "\n",
    "#add overall title to plot\n",
    "plt.title('Confusion matrix for COPA', fontsize = 12) # title with fontsize 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7863f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = [i for i in range(len(y_preds)) if ((y_preds[i] != y_true[i]) and (y_true[i]==0) and (y_preds[i]==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fce66a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_dataset = test_dataset.select(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88848d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'दफ्तर बंद था।',\n",
       " 'choice1': 'छुट्टी का दिन था।',\n",
       " 'choice2': 'गर्मी का मौसम था।',\n",
       " 'question': 'cause',\n",
       " 'idx': 4,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2dbd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\"my_awesome_swag_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

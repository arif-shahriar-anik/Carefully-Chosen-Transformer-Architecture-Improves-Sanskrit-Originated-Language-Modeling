{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fd6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c9a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e38c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "train_df = pd.DataFrame(columns=['id', 'ner_tags', 'tokens'])\n",
    "val_df = pd.DataFrame(columns=['id', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c641f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_file(file_path, df):\n",
    "    data = open(file_path, mode=\"r\", encoding=\"utf-8\")\n",
    "    raw_text = data.read().strip()\n",
    "\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "\n",
    "    for idx,doc in enumerate(raw_docs):\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        example_id = ''\n",
    "        for line in doc.split('\\n'):\n",
    "            if line.startswith('#'):\n",
    "                example_id = line\n",
    "                continue\n",
    "            token, tag = line.split('_ _')\n",
    "            tokens.append(token.strip())\n",
    "            tags.append(tag.strip())\n",
    "    #         print(token)\n",
    "    #         print(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "\n",
    "        df.loc[idx] = pd.Series({'id':example_id,'ner_tags':tags, 'tokens':tokens})\n",
    "    return df, token_docs, tag_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de6974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,_,tag_docs = read_conll_file(\"../datasets/BN-Bangla/bn_train.conll\", train_df)\n",
    "val_df, _,_ = read_conll_file(\"../datasets/BN-Bangla/bn_dev.conll\", val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513f03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5090906",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DatasetDict()\n",
    "datasets['train'] = train_ds\n",
    "datasets['validation'] = val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad80cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['২০১৮',\n",
       " 'এর',\n",
       " 'সেরা',\n",
       " '(বর্ণানুক্রমিকভাবে',\n",
       " 'তালিকাভুক্ত,',\n",
       " 'র\\u200d্যাঙ্ক',\n",
       " 'করা',\n",
       " 'হয়নি),',\n",
       " 'এনপিআর']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d7228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396bdacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['২০১৮',\n",
       " 'এর',\n",
       " 'সেরা',\n",
       " '(বর্ণানুক্রমিকভাবে',\n",
       " 'তালিকাভুক্ত,',\n",
       " 'র\\u200d্যাঙ্ক',\n",
       " 'করা',\n",
       " 'হয়নি),',\n",
       " 'এনপিআর']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900a4eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67766a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# id 5e80f5c9-1196-4906-826b-4cbdcaec7b6f\\tdomain=train'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ed4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set from list\n",
    "expanded_tag_docs = []\n",
    "\n",
    "for tags in tag_docs:\n",
    "    for tag in tags:\n",
    "        expanded_tag_docs.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d767792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CORP',\n",
       " 'B-CW',\n",
       " 'B-GRP',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'B-PROD',\n",
       " 'I-CORP',\n",
       " 'I-CW',\n",
       " 'I-GRP',\n",
       " 'I-LOC',\n",
       " 'I-PER',\n",
       " 'I-PROD',\n",
       " 'O'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags = set(expanded_tag_docs)\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf3afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(examples):\n",
    "    mapping = {'B-CORP':0,'B-CW':1,'B-GRP':2, 'B-LOC':3, 'B-PER':4, 'B-PROD':5, 'I-CORP':6, 'I-CW':7, 'I-GRP':8,\\\n",
    "               'I-LOC':9,'I-PER':10,'I-PROD':11,'O':12}\n",
    "    ner_labels = []\n",
    "    for example in examples[\"ner_tags\"]:\n",
    "        ner_labels.append(mapping[example])\n",
    "    examples[\"ner_labels\"] = ner_labels\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938d62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {' B-CORP':0,' B-CW':1,' B-GRP':2, ' B-LOC':3, ' B-PER':4, ' B-PROD':5, ' I-CORP':6, ' I-CW':7, ' I-GRP':8,\\\n",
    "#                ' I-LOC':9,' I-PER':10,' I-PROD':11,' O':12}\n",
    "# ner_labels = list()\n",
    "# examples = dataset[0]\n",
    "# for example in examples[\"ner_tags\"]:\n",
    "#     print(example)\n",
    "#     ner_labels.append(mapping[example])\n",
    "# examples[\"ner_labels\"] = ner_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d108be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8340ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1549a7ec640b1a6bb28939cd2aa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15300 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9aa73210f746a8b28cceadc89e590b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = datasets.map(assign_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e8b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"../Bengali Pretraining/models/unigram/bert-base-pretrained-bengali\"\n",
    "model_checkpoint = \"../Bengali Pretraining/models/unigram/unigram-long-text\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76204dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁',\n",
       " '২০১৮',\n",
       " '▁এর',\n",
       " '▁সেরা',\n",
       " '▁',\n",
       " '(',\n",
       " 'বর্ণ',\n",
       " 'ানু',\n",
       " 'ক্র',\n",
       " 'মিক',\n",
       " 'ভাবে',\n",
       " '▁তালিকাভুক্ত',\n",
       " ',',\n",
       " '▁',\n",
       " 'র\\u200d্যা',\n",
       " 'ঙ্ক',\n",
       " '▁করা',\n",
       " '▁হয়নি',\n",
       " '),',\n",
       " '▁এ',\n",
       " 'ন',\n",
       " 'পিআর',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1362bf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 5, 6, 7, 7, 8, 8, 8, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c024cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025aac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 12, 12, 12, 12, 12, 0]\n",
      "[-100, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = datasets[\"train\"][0][\"ner_labels\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c74e05e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '# id 5e80f5c9-1196-4906-826b-4cbdcaec7b6f\\tdomain=train',\n",
       " 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP'],\n",
       " 'tokens': ['২০১৮',\n",
       "  'এর',\n",
       "  'সেরা',\n",
       "  '(বর্ণানুক্রমিকভাবে',\n",
       "  'তালিকাভুক্ত,',\n",
       "  'র\\u200d্যাঙ্ক',\n",
       "  'করা',\n",
       "  'হয়নি),',\n",
       "  'এনপিআর'],\n",
       " '__index_level_0__': 0,\n",
       " 'ner_labels': [12, 12, 12, 12, 12, 12, 12, 12, 0]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a453d95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-CORP',\n",
       " 'B-CW',\n",
       " 'B-GRP',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'B-PROD',\n",
       " 'I-CORP',\n",
       " 'I-CW',\n",
       " 'I-GRP',\n",
       " 'I-LOC',\n",
       " 'I-PER',\n",
       " 'I-PROD',\n",
       " 'O']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'B-CORP':0,'B-CW':1,'B-GRP':2, 'B-LOC':3, 'B-PER':4, 'B-PROD':5, 'I-CORP':6, 'I-CW':7, 'I-GRP':8,\\\n",
    "               'I-LOC':9,'I-PER':10,'I-PROD':11,'O':12}\n",
    "label_names = list()\n",
    "for k, v in mapping.items():\n",
    "    label_names.append(k)\n",
    "\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab80b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cef56df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9193dc07ae64a7a9b1f5d51d8143fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce747aef6474f18be404894efa9bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043f5b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15300\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb0a320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637fe4b2d8104c09baf5c5118e25202a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6025356607fe4f16959915dc90b1de45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = tokenized_datasets.filter(lambda x:x if 0 in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05f8f9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 530\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59f18463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8846f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "           12,   12,   12,   12,   12,   12,   12,   12,    0,    0,    0, -100],\n",
       "        [-100,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "            2,    8,   12,   12, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91d6fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, -100]\n",
      "[-100, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 2, 8, 12, 12, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "573f73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27c696da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "932d41bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = datasets[\"train\"][0][\"ner_labels\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "752721fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CORP': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'overall_precision': 0.5,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 0.6666666666666666,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = 'B-CORP'\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2508b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bbed15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af8fc59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-CORP',\n",
       " 1: 'B-CW',\n",
       " 2: 'B-GRP',\n",
       " 3: 'B-LOC',\n",
       " 4: 'B-PER',\n",
       " 5: 'B-PROD',\n",
       " 6: 'I-CORP',\n",
       " 7: 'I-CW',\n",
       " 8: 'I-GRP',\n",
       " 9: 'I-LOC',\n",
       " 10: 'I-PER',\n",
       " 11: 'I-PROD',\n",
       " 12: 'O'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e935fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CORP': 0,\n",
       " 'B-CW': 1,\n",
       " 'B-GRP': 2,\n",
       " 'B-LOC': 3,\n",
       " 'B-PER': 4,\n",
       " 'B-PROD': 5,\n",
       " 'I-CORP': 6,\n",
       " 'I-CW': 7,\n",
       " 'I-GRP': 8,\n",
       " 'I-LOC': 9,\n",
       " 'I-PER': 10,\n",
       " 'I-PROD': 11,\n",
       " 'O': 12}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4010f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce240f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ca86d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"models/ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16c8b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dffbf869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashahri1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\Documents\\Sanskrit Language Model\\Bangla NER\\wandb\\run-20230905_140024-1yrpchvu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ashahri1/huggingface/runs/1yrpchvu\" target=\"_blank\">glamorous-frog-23</a></strong> to <a href=\"https://wandb.ai/ashahri1/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.643169641494751,\n",
       " 'eval_precision': 0.008607872290476564,\n",
       " 'eval_recall': 0.07119741100323625,\n",
       " 'eval_f1': 0.015358838313320305,\n",
       " 'eval_accuracy': 0.07768871075484302,\n",
       " 'eval_runtime': 4.7965,\n",
       " 'eval_samples_per_second': 166.788,\n",
       " 'eval_steps_per_second': 20.849}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fab434ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5739' max='5739' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5739/5739 07:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.260990</td>\n",
       "      <td>0.555341</td>\n",
       "      <td>0.558576</td>\n",
       "      <td>0.556954</td>\n",
       "      <td>0.918838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.219278</td>\n",
       "      <td>0.635645</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.655378</td>\n",
       "      <td>0.933868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.240201</td>\n",
       "      <td>0.672874</td>\n",
       "      <td>0.701618</td>\n",
       "      <td>0.686946</td>\n",
       "      <td>0.938878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5739, training_loss=0.2064756565256845, metrics={'train_runtime': 461.6532, 'train_samples_per_second': 99.425, 'train_steps_per_second': 12.431, 'total_flos': 755261516740392.0, 'train_loss': 0.2064756565256845, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a0676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

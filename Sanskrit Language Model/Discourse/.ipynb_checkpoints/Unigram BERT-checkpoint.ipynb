{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a436b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3a3d5814a8cfcd9e\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-3a3d5814a8cfcd9e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\\\midas-discourse\\\\hi\\\\train.json\", \\\n",
    "                             split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b0cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3541c228aae61542\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-3541c228aae61542/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "val_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\\\midas-discourse\\\\hi\\\\val.json\", \\\n",
    "                             split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4add36fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1b196b1d18f05fca\n",
      "Found cached dataset json (C:/Users/arifa/.cache/huggingface/datasets/json/default-1b196b1d18f05fca/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files=\"..\\datasets\\\\midas-discourse\\\\hi\\\\test.json\", \\\n",
    "                             split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f43ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "datasets = DatasetDict()\n",
    "datasets['train'] = train_dataset\n",
    "datasets['validation'] = val_dataset\n",
    "datasets['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fcd53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 7974\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5c43a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Story_no': [24, 19, 1, 47, 47],\n",
       " 'Sentence': ['पाँच साल गुजर गये।',\n",
       "  \" बिरजू के माँ ने आँगन से निकल गाँव की ओर कान लगा कर सुनने की चेष्टा की-' उँहुँ, इतनी देर तक भला पैदल जानेवाले रुके रहेंगे?' पूर्णिमा का चाँद सिर पर आ गया है।\",\n",
       "  ' कुछ लोग घर वाले होते हैं, कुछ लोग सीढ़ीयों के पीछे सोने वाले होते हैं, कुछ लोग गालियां देते हैं, कुछ लोग गालियां सहते हैं।',\n",
       "  'राम खिलावन ने अपनी कोठरी में जाकर अन्दर से दरवाज़ा लगा लिया और लाठी को चूल्हे में जला दी।',\n",
       "  \" इन्होंने कहा' शहर कोतवाल का अधिकार पूर्ण शब्द उनके कानों में गूंज गया।\"],\n",
       " 'Discourse Mode': ['Narrative',\n",
       "  'Narrative',\n",
       "  'Descriptive',\n",
       "  'Narrative',\n",
       "  'Dialogue'],\n",
       " 'id': ['4669', '3296', '237', '9030', '9082']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11ba956",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c4a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = datasets[\"train\"][\"Discourse Mode\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58793234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descriptive      2912\n",
       "Narrative        2489\n",
       "Dialogue         2361\n",
       "Argumentative     105\n",
       "Informative        67\n",
       "Other              40\n",
       "Name: Discourse Mode, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9381bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93161d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e786f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    #return tokenizer(example['Sentence'], truncation=True)\n",
    "    return tokenizer(example[\"Sentence\"], truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c36faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 7974\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Story_no', 'Sentence', 'Discourse Mode', 'id'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f2b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-3a3d5814a8cfcd9e\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-1da3b2109297219a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-3541c228aae61542\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-d2a0445ddd203610.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-1b196b1d18f05fca\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-c02832e51825428c.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, remove_columns=['Story_no', 'Sentence', 'id'])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0aee19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Discourse Mode', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7974\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Discourse Mode', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Discourse Mode', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49632e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\n",
    "    \"Descriptive\":0,\n",
    "    \"Narrative\":1,\n",
    "    \"Dialogue\":2,\n",
    "    \"Argumentative\":3,\n",
    "    \"Informative\":4,\n",
    "    \"Other\":5\n",
    "    }\n",
    "    example['labels'] = mapping[example['Discourse Mode']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde6a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-3a3d5814a8cfcd9e\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-ebce8a6d8387e6fd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-3541c228aae61542\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-12aee0f226282a86.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\json\\default-1b196b1d18f05fca\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-a63666a64de42380.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       " 'validation': ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       " 'test': ['input_ids', 'token_type_ids', 'attention_mask', 'labels']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(assign_label).remove_columns('Discourse Mode')\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10fec258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] पाँच साल गुजर गये।[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] बिरजू के माँ ने आँगन से निकल गाँव की ओर कान लगा कर सुनने की चेष्टा की-[UNK] उँहुँ, इतनी देर तक भला पैदल जानेवाले रुके रहेंगे?[UNK] पूर्णिमा का चाँद सिर पर आ गया है।[SEP]'\n",
      "\n",
      "'>>> [CLS] कुछ लोग घर वाले होते हैं, कुछ लोग सीढ़ीयों के पीछे सोने वाले होते हैं, कुछ लोग गालियां देते हैं, कुछ लोग गालियां सहते हैं।[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] राम खिलावन ने अपनी कोठरी में जाकर अन्दर से दरवाज़ा लगा लिया और लाठी को चूल्हे में जला दी।[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] इन्होंने कहा[UNK] शहर कोतवाल का अधिकार पूर्ण शब्द उनके कानों में गूंज गया।[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(5)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d45133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Story_no': [24, 19, 1, 47, 47],\n",
       " 'Sentence': ['पाँच साल गुजर गये।',\n",
       "  \" बिरजू के माँ ने आँगन से निकल गाँव की ओर कान लगा कर सुनने की चेष्टा की-' उँहुँ, इतनी देर तक भला पैदल जानेवाले रुके रहेंगे?' पूर्णिमा का चाँद सिर पर आ गया है।\",\n",
       "  ' कुछ लोग घर वाले होते हैं, कुछ लोग सीढ़ीयों के पीछे सोने वाले होते हैं, कुछ लोग गालियां देते हैं, कुछ लोग गालियां सहते हैं।',\n",
       "  'राम खिलावन ने अपनी कोठरी में जाकर अन्दर से दरवाज़ा लगा लिया और लाठी को चूल्हे में जला दी।',\n",
       "  \" इन्होंने कहा' शहर कोतवाल का अधिकार पूर्ण शब्द उनके कानों में गूंज गया।\"],\n",
       " 'Discourse Mode': ['Narrative',\n",
       "  'Narrative',\n",
       "  'Descriptive',\n",
       "  'Narrative',\n",
       "  'Dialogue'],\n",
       " 'id': ['4669', '3296', '237', '9030', '9082']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "568b8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4781049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model =  AutoModelForSequenceClassification.from_pretrained(\"../Hindi Pretraining/models/unigram/bert-base-pretrained-hindi\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f500c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_fun = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_result = metric_fun.compute(references=labels, predictions=predictions)\n",
    "    return {\n",
    "        \"accuracy\": metric_result[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d090707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "166eac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    report_to = None,\n",
    "    output_dir=\"models/bert-unigram-hindi-classifier\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #learning_rate=2e-5,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.02,\n",
    "    warmup_ratio = 0.1,\n",
    "    #warmup_ratio = 0.05,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    #num_train_epochs=4,\n",
    "    num_train_epochs=3,\n",
    "    #push_to_hub=True,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a602033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #train_dataset=entire_train,\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    #eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aba871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8767454624176025,\n",
       " 'eval_accuracy': 0.04714142427281846,\n",
       " 'eval_runtime': 3.0659,\n",
       " 'eval_samples_per_second': 325.189,\n",
       " 'eval_steps_per_second': 10.437}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b4e616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 02:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.778300</td>\n",
       "      <td>0.598496</td>\n",
       "      <td>0.787362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.576113</td>\n",
       "      <td>0.789368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.794383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.5046688222090403, metrics={'train_runtime': 121.5243, 'train_samples_per_second': 196.849, 'train_steps_per_second': 6.172, 'total_flos': 881933680545624.0, 'train_loss': 0.5046688222090403, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2722f884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5997897386550903,\n",
       " 'eval_accuracy': 0.8144433299899699,\n",
       " 'eval_runtime': 1.5024,\n",
       " 'eval_samples_per_second': 663.621,\n",
       " 'eval_steps_per_second': 21.3,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd0eaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6923bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ea8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

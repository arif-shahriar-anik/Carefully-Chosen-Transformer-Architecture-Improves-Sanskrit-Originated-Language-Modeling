{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abd764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d2eb08c671f6e225\n",
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-d2eb08c671f6e225/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "qa_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\Bengali Question Classification.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1c1826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Label'],\n",
       "    num_rows: 3333\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecadf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = qa_dataset[\"Label\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9983ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUMERIC         889\n",
       "HUMAN           651\n",
       "LOCATION        611\n",
       "ABBREVIATION    502\n",
       "ENTITY          482\n",
       "DESCRIPTION     198\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed49cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length = max(qa_dataset['Text'].str.len())\n",
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf07240",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a25d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f829941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../Bengali Pretraining/models/unigram/unigram-long-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe21642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model =  AutoModelForSequenceClassification.from_pretrained(\"../Bengali Pretraining/models/unigram/unigram-long-text\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78dd8459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab199977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"Text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f64d4d09720ceefe.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_dataset = qa_dataset.map(tokenize_function, batched=True, remove_columns=[\"Text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8451fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3333\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4235ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6acea022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-8a96610ce83393a5.arrow\n"
     ]
    }
   ],
   "source": [
    "temp = tokenized_dataset.filter(lambda x:x if 0 in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0d1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {'ABBREVIATION':0, 'DESCRIPTION':1, 'ENTITY':2, 'HUMAN':3, 'LOCATION':4, 'NUMERIC':5}\n",
    "    example['Label'] = mapping[example['Label']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a46142a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-aff11a5e1093dca2.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.map(assign_label)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"Label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fbdeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] পাটের জেনেটিক ম্যাপ কোন দেশের বিজ্ঞানী আবিষ্কার করেছেন[SEP][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] ভারতীয় কৃষিজ পণ্যের অন্যতম আমদানিকারক দেশ কোনটি[SEP][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] বিশ্বের সর্ববৃহত্ জনসংখ্যার দেশ কোনটি[SEP][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] কোন দেশে খাদ্য ঘাটতি নেই[SEP][PAD][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] আমাদের দেশের হাইব্রিড ধান বীজের বড় জোগানদার কোন দেশ[SEP]'\n",
      "\n",
      "'>>> [CLS] বিশ্বের অন্যতম প্রধান চাল রপ্তানিকারক দেশ কোনটি[SEP][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] I[UNK]I এর সদর দপ্তর কোথায় অবস্থিত[SEP][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] কোন দেশের জনসংখ্যা তুলনামূলকভাবে কম[SEP][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] সুপার হাইব্রিড ধানের উদ্ভাবক কোন দেশ[SEP][PAD][PAD][PAD][PAD][PAD]'\n",
      "\n",
      "'>>> [CLS] [UNK]I কোথায় অবস্থিত[SEP][PAD][PAD][PAD][PAD][PAD][PAD]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_dataset[i] for i in range(10)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93559af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ed528a230a4e08ea.arrow and C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ebe273b5c8914eff.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2666\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 667\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_dataset = tokenized_dataset.train_test_split(\n",
    "    #train_size=0.8, seed=42\n",
    "    train_size=0.8, seed=30\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size=32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    downsampled_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    downsampled_dataset[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ccc01a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([32]),\n",
       " 'input_ids': torch.Size([32, 20]),\n",
       " 'token_type_ids': torch.Size([32, 20]),\n",
       " 'attention_mask': torch.Size([32, 20])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72da652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7668) torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b73d49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b82cd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2,\n",
       "        2, 2, 4, 4, 2, 2, 2, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d15803ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2d7af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "# num_epochs = 3\n",
    "num_epochs = 4\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e30025b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad4e89f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd478397b91440a4911d4bf0d86a9a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0bac603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "# results = f1_metric.compute(predictions=[0, 1], references=[0, 1], average=\"macro\")\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f387e04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9696489454993822}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_preds =[ ]\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    y_preds.extend(predictions.tolist())\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute(average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d30b307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41c85b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = downsampled_dataset[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfb16022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "ABBREVIATION       1.00      0.98      0.99       101\n",
      " DESCRIPTION       0.90      0.93      0.92        29\n",
      "      ENTITY       0.96      0.97      0.96        90\n",
      "       HUMAN       0.96      0.99      0.98       124\n",
      "    LOCATION       1.00      0.98      0.99       123\n",
      "     NUMERIC       0.99      0.98      0.99       200\n",
      "\n",
      "    accuracy                           0.98       667\n",
      "   macro avg       0.97      0.97      0.97       667\n",
      "weighted avg       0.98      0.98      0.98       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['ABBREVIATION', 'DESCRIPTION', 'ENTITY', 'HUMAN', 'LOCATION', 'NUMERIC']\n",
    "print(classification_report(y_true, y_preds,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0aeacfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion matrix for QC')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#plot heatmap of confusion matrix\n",
    "mat = confusion_matrix(y_true, y_preds)\n",
    "heatmap(mat, cmap=\"Pastel1_r\", fmt=\"d\", xticklabels=target_names, yticklabels=target_names, annot=True)\n",
    "\n",
    "#add overall title to plot\n",
    "plt.title('Confusion matrix for QC', fontsize = 12) # title with fontsize 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b91322a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-cbbb3b1cccd1bf89.arrow\n"
     ]
    }
   ],
   "source": [
    "temp = qa_dataset.filter(lambda x:x if x[\"Label\"]=='ENTITY' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "184fdc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': ['বাংলাদেশ, ভারত, চীন ও ভিয়েতনাম এ চারটি দেশের  প্রধান উত্পাদিত ফসল কোনটি',\n",
       "  'বাংলাদেশ, ভারত, চীন ও ভিয়েতনামের মানুষদের প্রধান খাদ্য কী',\n",
       "  'আমাদের দেশে পরীক্ষামূলকভাবে গ্রিন হাউজে কোন সবজিগুলোর চাষ হচ্ছে',\n",
       "  'মৌসুম নির্ভরতা কাটিয়ে ওঠার লক্ষ্যে জিনগত পরিবর্তন সাধন করে কোন ফসল পাওয়া যায়',\n",
       "  'সংকরায়ন ও ক্রমাগত নির্বাচনের মাধ্যমে অর্জিত ফসলকে কী বলে',\n",
       "  'টিউব লাইটে সাধারনত কোন গ্যাস ব্যবহৃত হয়',\n",
       "  'ইইউ দেশগুলোর একক মুদ্রার নাম',\n",
       "  'কোন নির্বাচনে প্রেসিডেন্ট আইয়ুব খানের বিপক্ষে ফাতেমা জিন্নাহ দাড়িয়ে ছিলেন',\n",
       "  'বাংলাদেশের প্রথম বানিজ্য জাহাজ',\n",
       "  'বাংলাদেশের প্রথম রণতরী',\n",
       "  'প্রথম বাংলা চলচ্চিত্র',\n",
       "  'ইন্টারনেটের মাধ্যমে কম খরচে ফোন করার প্রযুক্তির নাম কি',\n",
       "  'বাংলাদেশ বেতার থেকে কোন কোন ভাষায় অনুষ্ঠান সমপ্রচার করা হয়',\n",
       "  'বাংলাদেশ টেলিভিশনের প্রথম নাটক কোনটি',\n",
       "  'বাংলাদেশে টেলিভিশনের প্রথম অনুষ্ঠান কি',\n",
       "  'বাংলাদেশ টেলিভিশনের প্রথম টিভি সিরিয়ালের নাম কি',\n",
       "  'বাংলাদেশের জাতীয় প্রতীক কি',\n",
       "  'জাতীয় সংসদের প্রতীক কি',\n",
       "  'ইন্দোনেশিয়ার জাতীয় প্রতীক কি',\n",
       "  'চীনের বিমানের প্রতীক কি',\n",
       "  'মৌর্যদের রাজকীয় প্রতীক কি ছিল',\n",
       "  'বাংলাদেশের জাতীয় সংগীত কোনটি',\n",
       "  'আমার সোনার বাংলা রবীন্দ্রনাথ ঠাকুরের কোন গ্রন্থের অর্ন্তগত',\n",
       "  'আমার সোনার বাংলা প্রথম প্রকাশিত হয় কোন পত্রিকায়',\n",
       "  'বাংলাদেশের রণ সংগীত চল্\\u200c চল্\\u200c চল্\\u200c কোন কাব্যর অর্ন্তগত',\n",
       "  'রণ সঙ্গীত কোন পত্রিকায় প্রকাশিত হয়',\n",
       "  'বাংলাদেশের ক্রীড়া সংগীত কোনটি',\n",
       "  'বাংলাদেশের জলবায়ু কিরূপ',\n",
       "  'বাংলাদেশের জলবায়ূ কি নামে পরিচিত',\n",
       "  'বাংলাদেশের জাতীয় ফুলের নাম কি',\n",
       "  'বাংলাদেশের জাতীয় পশুর নাম কি',\n",
       "  'ভারতের জাতীয় পশুর নাম কি',\n",
       "  'সব চেয়ে বড় পশুর নাম কি',\n",
       "  'সব চেয়ে ছোট পশুর নাম কি',\n",
       "  'সব চেয়ে দ্রুত পশুর নাম কি',\n",
       "  'সব চেয়ে বিপজ্জনক পশুর নাম কি',\n",
       "  'সব চেয়ে  চালাক পশুর নাম কি',\n",
       "  'বাংলাদেশের জাতীয় বনের নাম কি',\n",
       "  'বাংলাদেশের জাতীয় মাছের নাম কি',\n",
       "  'বাংলাদেশের জাতীয় খেলা কোনটি',\n",
       "  'পৃথিবীতে সবচেয়ে প্রাচীন খেলা কোনটি',\n",
       "  'পৃথিবীতে সবচেয়ে প্রিয় খেলা কোনটি',\n",
       "  'ছোট বেলায় আপনার প্রিয় খেলা কোনটি',\n",
       "  'বাংলাদেশের সব চেয়ে জনপ্রিয় খেলা কোনটি',\n",
       "  'ভূটানের জাতীয় খেলা কোনটি',\n",
       "  'কম্পিউটার গেম কোনটি',\n",
       "  'রাজিবের পছন্দের খেলা কোনটি',\n",
       "  'ভারতের জাতীয় খেলা কোনটি',\n",
       "  'চাকমারা খেলতে ভালোবাসে এমন খেলা কোনটি',\n",
       "  'বাংলাদেশের জাতীয় ফল কোনটি',\n",
       "  'ভারত এর  জাতীয় উৎসব কোনটি',\n",
       "  'নেপাল এর  জাতীয় উৎসব কোনটি',\n",
       "  'জাপান এর  জাতীয় উৎসব কোনটি',\n",
       "  'চীন এর  জাতীয় উৎসব কোনটি',\n",
       "  'বাংলাদেশের জাতীয় উৎসব কোনটি',\n",
       "  'মুসলমানদের সবচেয়ে বড় উৎসব কোনটি',\n",
       "  'হিন্দুদের সবচেয়ে বড় উৎসব কোনটি',\n",
       "  'খ্রীষ্টানদের সবচেয়ে বড় উৎসব কোনটি',\n",
       "  'বৌদ্ধদের সবচেয়ে বড় উৎসব কোনটি',\n",
       "  'আন্তর্জাতিক উৎসব কোনটি',\n",
       "  'কৃষি কাজের জন্য সর্বাপেক্ষা উপযোগী মাটি',\n",
       "  'বাংলাদেশের প্রধান অর্থকরী ফসল কি',\n",
       "  'বাংলাদেশের দ্বিতীয় অর্থকরী ফসল কি',\n",
       "  'রবি শস্য বলতে বুঝায়',\n",
       "  'খরিপ শস্য বলতে বুঝায়',\n",
       "  'সরকার কৃষকের স্বার্থে কোন সার আমদানী নিষিদ্ধ করেছে',\n",
       "  'কোন জাতের ছাগল বাংলাদেশে সর্বাপেক্ষা বেশী পাওয়া যায়',\n",
       "  'ভারতের বিহার রাজ্যের যমুনা পাড়ের ছাগল বংশধর বাংলাদেশে কি নামে পরিচিত',\n",
       "  'সুন্দরবনের প্রধান বৃক্ষ কোনটি',\n",
       "  'কোন কাঠ থেকে বাক্স ও দিয়াশলাইয়ের কাঠি প্রস্তুত হয়',\n",
       "  'ধুন্দল গাছের কাঠ থেকে কি প্রস্তুত করা হয়',\n",
       "  'কোন গাছের ছাল থেকে রং প্রস্তুত করা হয়',\n",
       "  'কোন জাতীয় গাছ সবচেয়ে বেশী বৃদ্ধি পায়',\n",
       "  'মধুপুর বনাঞ্চলের প্রধান বৃক্ষ কি',\n",
       "  'কোন গাছ কে সুর্যের কন্যা বলা হয়',\n",
       "  'বাংলাদেশের দীর্ঘতম গাছের নাম কি',\n",
       "  'ক্রান্তীয় বনাঞ্চলের প্রধান গাছ হল কোনটি',\n",
       "  'পরিবেশ রক্ষার ক্ষেত্রে কোন গাছটি ক্ষতিকারক',\n",
       "  'প্রানিজ আমিষের প্রধান উৎস কি',\n",
       "  'বাংলাদেশের প্রধান প্রাণিজ সম্পদ',\n",
       "  'পুকুরে কোন মাছ বাচেঁ না',\n",
       "  'প্রানিজ আমিষের প্রধান উৎস কি',\n",
       "  'বাংলাদেশের প্রধান খনিজ সম্পদ কি',\n",
       "  'প্রাকৃত গ্যাস কি',\n",
       "  'খনিজ তেল কি',\n",
       "  'বাংলাদেশ  কোন ধরনের পণ্য রপ্তানি করে',\n",
       "  'বাংলাদেশ  কোন ধরনের পণ্য আমদানি করে',\n",
       "  'ভারত  কোন ধরনের পণ্য রপ্তানি করে',\n",
       "  'ভারত  কোন ধরনের পণ্য আমদানি করে',\n",
       "  'নেপাল  কোন ধরনের পণ্য রপ্তানি করে',\n",
       "  'নেপাল  কোন ধরনের পণ্য আমদানি করে',\n",
       "  'চীন কোন ধরনের পণ্য রপ্তানি করে',\n",
       "  'চীন  কোন ধরনের পণ্য আমদানি করে',\n",
       "  'বাংলাদেশের প্রধান খনিজ সম্পদ কি',\n",
       "  'প্রাকৃত গ্যাস কি',\n",
       "  'কর্নফুলী পেপার মিলের কাঁচামাল কি',\n",
       "  'পাকশী পেপার মিলের কাঁচামাল কি',\n",
       "  'ইউরিয়া সারের প্রধান কাঁচামাল কি',\n",
       "  'বাংলাদেশ পুলিশের মনোগ্রাম থেকে কি বাদ দেয়া হয়েছিল',\n",
       "  'বাংলাদেশ নৌবাহিনীর প্রথম রণতরীর নাম কি',\n",
       "  'বাংলাদেশ নৌবাহিনীর প্রতীক কি',\n",
       "  'বাংলাদেশ সেনাবাহিনীর প্রতীক কি',\n",
       "  'বাংলাদেশ ভিডিপি বাহিনীর প্রতীক কি',\n",
       "  'বাংলাদেশ বিডি পুলিশ  বাহিনীর প্রতীক কি',\n",
       "  'জাতিসংঘ প্রতীক কি',\n",
       "  'ঢাকা ময়মনসিংহ অঞ্চলের ঐতিহ্যবাহী নৃত্য গীতের নাম কি',\n",
       "  'বাংলাভাষার আদি নিদর্শন কি',\n",
       "  'উপমহাদেশের প্রথম ও বাংলায় সবাক চলচ্চিত্র কোনটি',\n",
       "  'উপহমাদেশের প্রথম নির্বাক চলচ্চিত্রের নাম কি',\n",
       "  'বাংলাদেশের প্রথম চলচ্চিত্র কোনটি',\n",
       "  'অস্কার পুরস্কার প্রাপ্ত একমাত্র বাংলা চলচ্চিত্র কোনটি',\n",
       "  'বাংলাদেশের প্রথম প্রামান্য চিত্রের নাম কি',\n",
       "  'এফডিসিতে নির্মিত প্রথম ছবি কোনটি',\n",
       "  'এফডিসির প্রথম মুক্তিপ্রাপ্ত ছবি কোনটি',\n",
       "  'ঢাকা ময়মনসিংহ অঞ্চলের ঐতিহ্যবাহী নৃত্য গীতের নাম কি',\n",
       "  'উপমহাদেশের প্রথম ও বাংলায় সবাক চলচ্চিত্র কোনটি',\n",
       "  'উপহমাদেশের প্রথম নির্বাক চলচ্চিত্রের নাম কি',\n",
       "  'বাংলাদেশের প্রথম চলচ্চিত্র কোনটি',\n",
       "  'অস্কার পুরস্কার প্রাপ্ত একমাত্র বাংলা চলচ্চিত্র কোনটি',\n",
       "  'জহির রায়হান পরিচালিত প্রথম চলচ্চিত্র কোনটি',\n",
       "  'জহির রায়হান পরিচালিত বিখ্যাত চলচ্চিত্রগুলো হল',\n",
       "  'বাংলাদেশের প্রথম প্রামান্য চিত্রের নাম কি',\n",
       "  'বনানী চৌধুরী অভিনীত প্রথম চলচ্চিত্র কোনটি',\n",
       "  'এফডিসিতে নির্মিত প্রথম ছবি কোনটি',\n",
       "  'এফডিসির প্রথম মুক্তিপ্রাপ্ত ছবি কোনটি',\n",
       "  'বিশ্বে সবচেয়ে বেশি লোক কথা বলে কোন ভাষায়',\n",
       "  'পানিনি রচিত গ্রন্থের নাম কি',\n",
       "  'পানিণি কোন ভাষার ব্যাকরণকে শৃঙ্খলাবদ্ধ করেন',\n",
       "  'বাংলা ভাষার মূল উৎস কোনটি',\n",
       "  'বাংলা ভাষা কোন আদি বা মূল ভাষা গোষ্ঠীর অর্ন্তগত',\n",
       "  'আর্য ভারতীয় গোষ্ঠীর প্রাচীনতম সাহিত্যেক ভাষার নাম কি',\n",
       "  'বাংলা ভাষার মূল উৎস কোন ভাষা',\n",
       "  'কোন ভাষা বৈদিক ভাষা নামে স্বীকৃত',\n",
       "  'কোন ভাষাকে প্রাকৃত ভাষা বলে',\n",
       "  'প্রাকৃত ভাষা বিবর্তিত হয়ে শেষ যে স্তরে উপনীত হয় তার নাম কি',\n",
       "  'সুনীত কুমার চট্টোপাধ্যায়ের মতে বাংলা ভাষার উদ্ভর কোন অপভ্রংশ থেকে কোন সময় কালে',\n",
       "  'ড. মুহাম্মদ শহীদুল্লাহর মতে বাংলা ভাষার উৎস কোন অপভ্রংশ থেকে',\n",
       "  'কোন ভাষা থেকে বাংলা ভাষার উৎপত্তি',\n",
       "  'বাংলা ছাড়া ব্রাহ্মী লিপি থেকে আর কোন লিপির উদ্ভদ ঘটেছে',\n",
       "  'ব্রাহ্মী লিপির বিবর্তনের ধারায় কোন বর্নমালা থেকে বাংলা বর্নমালার উৎপত্তি',\n",
       "  'ব্রাহ্মী লিপির পূর্ববর্তী লিপি কোনটি',\n",
       "  'ভারতীয় লিপিশালার প্রাচীনতম রূপ কোনটি',\n",
       "  'বাংলা লিপি ও বর্ণমালার উদ্ভব হয়েছে কোন লিপি থেকে',\n",
       "  'ব্রাহ্মী লিপির পূর্ববর্তী লিপি কোনটি',\n",
       "  'কোন কোন লিপির উপর বাংলা লিপির প্রভাব বিদ্যমান',\n",
       "  'চর্যাপদ কোন ভাষায় রচিত হয়',\n",
       "  'টীকাকার মুনিদত্তের মতানুসারে চর্যাপদের নাম কি',\n",
       "  'বাংলা ভাষার সঙ্গে মিল খুঁজে পাওয়া যায় কোন ভাষার',\n",
       "  'কোন লিপি থেকে বাংলা লিপির উদ্ভব ঘটেছে',\n",
       "  'ভারতের মৌলিক লিপি কোন লিপিকে বলা বলে',\n",
       "  'আধুনিকের পন্ডিতগণের মতে, নেপালে প্রাপ্ত চর্যাপদের পুঁথির নাম কি',\n",
       "  'চর্যাপদের পদগুলো কোন কোন ভাষায় রচিত বলে দাবি করা হয়',\n",
       "  'বাংলা ছাড়া কোন কোন বাব্যগ্রন্থে বাঙালী জীবনের চিত্র রয়েছে',\n",
       "  'আদি যুগে লোকজীবনের কথা বিধৃত সর্বপ্রথম সাহিত্যক নিদর্শন কোনটি',\n",
       "  'ব্রজবুলি ভাষা কোন জাতীয় ভাষা',\n",
       "  'বাংলা সাহিত্যের প্রথম উপন্যাস কোনটি',\n",
       "  'বাংলা ভাষায় প্রথম সামাজিক নাটক কোনটি',\n",
       "  'বাংলা সাহিত্যর প্রথম সার্থক ট্রাজেডি নাটক কোনটি',\n",
       "  'বাংলা সাহিত্যের প্রথম মূদ্রিত গ্রন্থ কোনটি',\n",
       "  'রোমান্টিক প্রণয় উপখ্যান ধারার অন্যতম গ্রন্থ',\n",
       "  'ঢাকা থেকে প্রকাশিত প্রথম গ্রন্থ কোনটি',\n",
       "  '‘গাজঅকালু ও চম্পাবতী’ কোন ধরনের সাহিত্য',\n",
       "  'গিয়াসউদ্দিন আজম শাহের পৃষ্ঠপোষকতায় শাহ মুহম্মদ সগীর কোন কাব্যটি রচনা করেন',\n",
       "  'মৈয়মনসিংহ গীতিকার অর্ন্তগত উল্লেখযোগ্য গীতিকাগুলো কি কি',\n",
       "  'মৈয়মনসিংহ গীতিকা বিশ্বের কয়টি ভাষায় অনুদিত হয়েছে',\n",
       "  'মধ্যযুগে ফারসি ভাষা থেকে অনুদিত প্রণয়োপাখ্যানগুলো কি কি',\n",
       "  'মধ্যযুগে হিন্দী ভাষা থেকে অনুদিত প্রণয়োপাখ্যানগুলো কি কি',\n",
       "  'মহাকবি মাইকেল মধুসূদন দত্ত এর মহাকাব্যের নাম কি',\n",
       "  'হেমচন্দ্র বন্দ্যোপাধ্যয় মহাকাব্যের নাম কি',\n",
       "  'নবীনচন্দ্র সেন মহাকাব্যের নাম কি',\n",
       "  'কায়কোবাদ মহাকাব্যের নাম কি',\n",
       "  'ইসমাইল হোসেন সিরাজী মহাকাব্যের নাম কি',\n",
       "  'আখরজ্জমান ইলিয়াস এর উপন্যাসের নাম কি কি',\n",
       "  'বঙ্কিমচন্দ্র চট্টোপাধ্যয় এর উপন্যাসের নাম কি কি',\n",
       "  'প্রভাত কুমার মুখোপাধ্যায় এর উপন্যাসের নাম কি কি',\n",
       "  'শরৎচন্দ্র চট্টোপাধ্যায় এর উপন্যাসের নাম কি কি',\n",
       "  'রমেশচন্দ্র দত্ত এর উপন্যাসের নাম কি কি',\n",
       "  'রবীন্দ্রনাথ ঠাকুর উপন্যাসের নাম কি কি',\n",
       "  'তারাশঙ্কর বন্দোপাধ্যায় উপন্যাসের নাম কি কি',\n",
       "  'মানিক বন্দোপাধ্যয় উপন্যাসের নাম কি কি',\n",
       "  'বিভূতিভূষণ বন্দোপাধ্যায় উপন্যাসের নাম কি কি',\n",
       "  'টেকচাঁদ ঠাকুর উপন্যাসের নাম কি কি',\n",
       "  'সৈয়দ ওয়ালীউল্লাহ উপন্যাসের নাম কি কি',\n",
       "  'রবীন্দ্রনাথ ঠাকুর এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'প্রভাতকুমার এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'সৈয়দ ওয়ালীউল্লাহ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'জহির রায়হান এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'সৈয়দ শামসুল হক এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'শরৎচন্দ্র চট্টোপাধ্যায় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'শওকত ওসমান এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'অন্নদাশঙ্কর রায় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'অচিন্ত্য কুমার সেনগুপ্ত এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবুল মনসুর আহমেদ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবুল ফজল এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবুল ফজল এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আকবর হোসেন এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবু রুশদ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবদুল হক এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবদুস শাকুর এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'সরদার জয়েনউদ্দীন এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবু ইসহাক এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'শামসুদ্দীন আবুল কালাম গল্পগ্রন্থের নাম কি কি',\n",
       "  'আলাউদ্দিন আল আজাদ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবুল কালাম মঞ্জর মোরশেদ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আহমেদ রফিক এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবদুল গাফফার চৌধুরী এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবদুল মান্নান সৈয়দ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আখতারুজ্জমান ইলিয়াস এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'ইব্রাহিম খাঁ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আবুল খায়ের মুসলেহ উদ্দিন এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'আল মাহমুদ এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'ত্রৈলোক্যনাথ মুখোপাধ্যয় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'কাজী নজরুল ইসলাম এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'ধূর্জটি প্রসাদ মুখোপাধ্যয় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'প্রমথ চৌধুরী এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'প্রেমেন্দ্র মিত্র এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'খালেদা এবিদ চৌধুরী এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'জসীম উদ্দিন এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'তারাশঙ্কর বন্দোপাধ্যয় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'বিভূতিভূষণ বন্দোপাধ্যয় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'বলাই চাঁদ মুখোপাধ্যায় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'বুদ্ধদেব বসু এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'সুফিয়া কামাল এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'হাসান হাফিজুর রহমান এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'মানিক বন্দোপাধ্যয় এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'রাহাত খান এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'শাহাদত আলী এর গল্পগ্রন্থের নাম কি কি',\n",
       "  'মমতাজ উদ্দীন আহমেদ এর নাটকের নাম কি কি',\n",
       "  'রবীন্দ্রনাথ ঠাকুর এর নাটকের নাম কি কি',\n",
       "  'হরচন্দ্র ঘোষ এর নাটকের নাম কি',\n",
       "  'যোগেন্দ্রচন্দ্র এর নাটকের নাম কি',\n",
       "  'তারাচরণ সিকদার এর নাটকের নাম কি',\n",
       "  'রামনারায়ন তর্ক রত্ন এর নাটকের নাম কি কি',\n",
       "  'নবীন চন্দ্র সেন এর নাটকের নাম কি',\n",
       "  'আনিস চৌধুরী এর নাটকের নাম কি কি',\n",
       "  'আকবর উদ্দিন এর নাটকের নাম কি কি',\n",
       "  'আশকার ইবনে শাইখ এর নাটকের নাম কি কি',\n",
       "  'মাইকেল মধুসুদন দত্ত এর নাটকের নাম কি কি',\n",
       "  'গিরিশচন্দ্র ঘোষ এর নাটকের নাম কি কি',\n",
       "  'দ্বিজেন্দ্রলাল রায় এর নাটকের নাম কি কি',\n",
       "  'আনম বজলুর রশীদ এর নাটকের নাম কি কি',\n",
       "  'আলী মনসুর এর নাটকের নাম কি',\n",
       "  'আবদুল্লাহ আল মামুন এর নাটকের নাম কি কি',\n",
       "  'ইব্রাহিম খাঁ এর নাটকের নাম কি কি',\n",
       "  'কাজী নজরুল ইসলাম এর নাটকের নাম কি কি',\n",
       "  'কৃষ্ণচন্দ্র হালদার এর নাটকের নাম কি কি',\n",
       "  'জসীমউদ্দিন এর নাটকের নাম কি কি',\n",
       "  'দীনবন্ধু মিত্র এর নাটকের নাম কি কি',\n",
       "  'নারায়ন গঙ্গোপাধ্যায় এর নাটকের নাম কি কি',\n",
       "  'নীলিমা ইব্রাহিম এর নাটকের নাম কি কি',\n",
       "  'নুরুল মোমেন এর নাটকের নাম কি কি',\n",
       "  'মুনীর চৌধুরী এর নাটকের নাম কি কি',\n",
       "  'মামুনুর রশীদ এর নাটকের নাম কি কি',\n",
       "  'শাহাদাৎ হোসেন এর নাটকের নাম কি কি',\n",
       "  'শওকত ওসমান এর নাটকের নাম কি কি',\n",
       "  'হেমচন্দ্র চট্রোপাধ্যায় এর নাটকের নাম কি',\n",
       "  'সিকান্দার আবু জাফর এর নাটকের নাম কি কি',\n",
       "  'হুমায়ুন আহমেদ এর নাটকের নাম কি কি',\n",
       "  'সৈয়দ ওয়ালী উল্লাহ এর নাটকের নাম কি কি',\n",
       "  'সাঈদ আহমদ এর নাটকের নাম কি কি',\n",
       "  'অমৃতলাল বসু এর নাটকের নাম কি কি',\n",
       "  'ক্ষীরোদপ্রসাধ বিদ্যাবিনোদ এর নাটকের নাম কি কি',\n",
       "  'সেলিম আলদীন এর নাটকের নাম কি কি',\n",
       "  'নাট্যকার আসকার ইবনে শাইখ এর নাটকের নাম কি',\n",
       "  'নাট্যকার আকবর উদ্দীন এর নাটকের নাম কি',\n",
       "  'নাট্যকার ইব্রাহিম খাঁ এর নাটকের নাম কি',\n",
       "  'নাট্যকার ইবরাহিম খলিল এর নাটকের নাম কি',\n",
       "  'নাট্যকার দ্বিজেন্দ্রলাল রায় এর নাটকের নাম কি',\n",
       "  'নাট্যকার গিরীশ চন্দ্র ঘোষ এর নাটকের নাম কি',\n",
       "  'নাট্যকার মধুসুধন দত্ত এর নাটকের নাম কি',\n",
       "  'নাট্যকার মহেন্দ্র গুপ্ত এর নাটকের নাম কি',\n",
       "  'নাট্যকার শচীন্দ্রনাথ সেন গুপ্ত এর নাটকের নাম কি',\n",
       "  'নাট্যকার মুনীর চৌধুরী এর নাটকের নাম কি',\n",
       "  'নাট্যকার রবীন্দ্রনাথ ঠাকুর এর নাটকের নাম কি',\n",
       "  'নাট্যকার সিকান্দার আবু জাফর এর নাটকের নাম কি',\n",
       "  'নাট্যকার শাহাদাৎ হোসেন এর নাটকের নাম কি',\n",
       "  'নাট্যকার ক্ষিরোদ প্রসাদ বিদ্যাবিনোদ এর নাটকের নাম কি',\n",
       "  'নাট্যকার আনিস চৌধুরী এর নাটকের নাম কি',\n",
       "  'নাট্যকার অমৃত লাল বসু এর নাটকের নাম কি',\n",
       "  'নাট্যকার আসকার ইবনে শাইখ এর নাটকের নাম কি',\n",
       "  'নাট্যকার গিরিশ চন্দ্র ঘোষ এর নাটকের নাম কি',\n",
       "  'নাট্যকার জ্যোতিরিন্দ্র নাথ ঠাকুর এর নাটকের নাম কি',\n",
       "  'নাট্যকার তুলসী লাহিড়ী এর নাটকের নাম কি',\n",
       "  'নাট্যকার রবীন্দ্র নাথ ঠাকুর এর নাটকের নাম কি',\n",
       "  'নাট্যকার সৈয়দ ওয়ালী উল্লাহ এর নাটকের নাম কি',\n",
       "  'নাট্যকার দীনবন্দু মিত্র এর নাটকের নাম কি',\n",
       "  'নাট্যকার বিজন ভট্ট্রচার্য এর নাটকের নাম কি',\n",
       "  'নাট্যকার মীর মোশারফ হোসেন এর নাটকের নাম কি',\n",
       "  'নাট্যকার দ্বিজেন্দ্রলাল রায় এর নাটকের নাম কি',\n",
       "  'নাট্যকার নূরুল মোমেন এর নাটকের নাম কি',\n",
       "  'নাট্যকার মুনীর চৌধুরী এর নাটকের নাম কি',\n",
       "  'নাট্যকার রাম নারায়ন তর্করত্ন এর নাটকের নাম কি',\n",
       "  'বাংলা সাহিত্যের প্রথম সনেট কে রচনা করেন',\n",
       "  'বাংলা ভাষার প্রথম ব্যাকরণ গ্রন্থ কোনটি',\n",
       "  'সুনীতকুমার চট্রোপাধ্যায় রচিত গ্রন্থের নাম কি',\n",
       "  'রামমোহন রায় এর ভাষাবিজ্ঞান বিষয়ক গ্রন্থ কি',\n",
       "  'শব্দতত্ত্ব ও বাংলা ভাষার পরিচয় কোন ভাষা বিজ্ঞনীর সৃষ্টি প্রবাহ',\n",
       "  'ভাষা বিজ্ঞানী ড. মুহাম্মদ শহীদুল্লাহ রচিত গ্রন্থের নাম',\n",
       "  'রামমোহন রায় এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'আবুল কালাম মনজুর মোরশেদ এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'মুহম্মদ দানীউল হক এর ভাষা বিষয়ক গ্রন্থ কি কি',\n",
       "  'ডঃ মুহম্মদ শহীদুল্লাহ এর ভাষা বিষয়ক গ্রন্থ কি কি',\n",
       "  'হুমায়ুন আজাদ এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'মনিরুজ্জামান এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'মুহম্মদ আব্দুল হাই এর ভাষা বিষয়ক গ্রন্থ কি কি',\n",
       "  'সুনীতকুমার চট্রোপাধ্যায় এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'শাজাহান মনির এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'ড. মুহম্মদ এনামুল হক এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'জগদীশ চন্দ্র ঘোষ এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'সুকুমার সেন এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'রবিন্দ্রনাথ ঠাকুর এর ভাষা বিষয়ক গ্রন্থ কি কি',\n",
       "  'মুনীর চৌধুরী এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'জামিল চৌধুরী এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'আজিজুল হক এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'নরেন বিশ্বাস এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'ডঃ মোহাম্মদ আবুল কাইউম এর ভাষা বিষয়ক গ্রন্থ কি কি',\n",
       "  'মুরারী মোহন সেন এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'রামেন্দ্র সুন্দর ত্রিবেদী এর ভাষা বিষয়ক গ্রন্থ কোনটি',\n",
       "  'খ্রিষ্টান মিশনারিদের হিন্দু প্রতিপক্ষ কর্তৃক প্রকাশিত পত্রিকা',\n",
       "  'রাম মোহন প্রথম সম্পাদনা করেন',\n",
       "  'মুসলমান সম্পাদিত প্রথম পত্রিকা',\n",
       "  'প্রথম সচিত্র মাসিক পত্রিকা কোনটি',\n",
       "  'কোন পত্রিকাকে ঘিরে রবীন্দ্রনাথ ঠাকুরের পূর্ন প্রতিভা বিকশিত হয়',\n",
       "  'মুসলিম সাহিত্য সমাজের মুখপাত্র হিসাবে প্রকাশিত পত্রিকা',\n",
       "  'কোন পত্রিকা কে বুদ্ধির মুক্তি আন্দোলনের সূত্রপাত ঘটেছিল',\n",
       "  'রংপুরের কাকিনা থেকে প্রকাশিত পত্রিকার নাম',\n",
       "  '“পদ্মাবতী” কোন জাতীয় রচনা',\n",
       "  'সতী ময়না ও লোরচন্দ্রানী হিন্দি ভাষার কোন কাব্য অবলম্বনে রচিত',\n",
       "  'উপমহাদেশের প্রথম ছাপাখানায় মুদ্রিত প্রথম বইয়ের নাম কি',\n",
       "  'ছাপার অক্ষরে প্রথম বাংলা বই কোনটি',\n",
       "  'বাংলা সাহিত্যে প্রথম মুদ্রিত গ্রন্থ কি',\n",
       "  'বাংলা সাহিত্যে প্রথম উপন্যাস কি',\n",
       "  'বাংলা ভাষার রচিত প্রথম প্রণোয়পখ্যান কি',\n",
       "  'বাংলা সাহিত্যে প্রথম রোমান্টিক উপন্যাস',\n",
       "  'বাংলা ভাষায় প্রথম ব্যকরণ',\n",
       "  'বাংলা ভাষায় রচিত প্রথম প্রবন্ধ গ্রন্থ',\n",
       "  'বাংলা ভাষায় রচিত প্রথম সামাজিক নাটক',\n",
       "  'বাংলা ভাষায় রচিত প্রথম প্রহসন নাটক',\n",
       "  'বাংলা ভাষায় রচিত প্রথম নাটক',\n",
       "  'বাংলা ভাষায় রচিত প্রথম ট্রাজেডি নাটক',\n",
       "  'বাংলা সাহিত্যের প্রথম মৌলিক ট্রাজেডি',\n",
       "  'আধুনিক বাংলা সাহিত্যের প্রথম কাব্য',\n",
       "  'বাংলা সাহিত্যের প্রথম মহাকাব্',\n",
       "  'বাংলা ভাষায় প্রকাশিত প্রথম সাময়িকী',\n",
       "  'মুসলমান সম্পাদিত প্রথম পত্রিকা',\n",
       "  'ঢাকা থেকে প্রকাশিত প্রথম গ্রন্থ',\n",
       "  'কাজী নজরুল ইসলামের প্রথম প্রকাশিত গল্প কি',\n",
       "  'বাংলাদেশের রণসঙ্গীত চল্ চল্ চল্ কোন কাব্যের অর্ন্তভুক্ত',\n",
       "  'বাংলাদেশের জাতীয় সংগীত ১৯০৫ সালে (বাংলা ১৩১২) বঙ্গদর্শন পত্রিকায় প্রকাশিত আমার সোনার বাংলা রবীন্দ্রনাথ ঠাকুরের কোন্ কাব্যগ্রন্থের অন্তর্গত',\n",
       "  'যে যন্ত্রের সাহায্যে কথা বলার সময় অপর প্রান্তের ব্যক্তির ছবি দেখা যায়, তাকে বলা হয়',\n",
       "  'সেনাবাহিনীর  জেনারেল পদের সমপর্যায়ের নৌবাহিনীর পদকে বলে',\n",
       "  'আন্তর্জাতিক পর্যায়ে পুরষ্কারপ্রাপ্ত বাংলাদেশের স্বল্প দৈর্ঘ্য চলচ্চিত্র হচ্চে',\n",
       "  'বাংলাদেশ শিপিং কর্পোরেশনের বৃহত্তর কনটেইনার জাহাজের নাম',\n",
       "  'বাংলাদেশের দ্বিতীয় অর্থকরী ফসল কোনটি',\n",
       "  'সূর্যের রঙ কি',\n",
       "  'কমলার রঙ কি',\n",
       "  'চাঁদের রঙ কি',\n",
       "  'আপনার গাড়ির রঙ কি',\n",
       "  'আপনার বাড়ির রং কি',\n",
       "  'কমলা রঙ কি',\n",
       "  'কলা রঙ কি',\n",
       "  'আম রঙ কি',\n",
       "  'পাতা রঙ কি',\n",
       "  'গাছ রঙ কি',\n",
       "  'যুক্তরাষ্ট্রের মুদ্রার নাম কি',\n",
       "  'আফগানিস্তানের মুদ্রার নাম কি',\n",
       "  'অস্ট্রেলিয়ার মুদ্রার নাম কি',\n",
       "  'আর্জেন্টিনার মুদ্রার নাম কি',\n",
       "  'কানাডার মুদ্রার নাম কি',\n",
       "  'চীন এর মুদ্রার নাম কি',\n",
       "  'কিউবার মুদ্রার নাম কি',\n",
       "  'ফ্রান্সের মুদ্রার নাম কি',\n",
       "  'ভারতের মুদ্রার নাম কি',\n",
       "  'ইরানের মুদ্রার নাম কি',\n",
       "  'ইরাকের মুদ্রার নাম কি',\n",
       "  'আয়ারল্যান্ডের মুদ্রার নাম কি',\n",
       "  'জাপানের মুদ্রার নাম কি',\n",
       "  'জাপানের মুদ্রার নাম কি',\n",
       "  'কুয়েতের মুদ্রার নাম কি',\n",
       "  'লাইবেরিয়ার মুদ্রার নাম কি',\n",
       "  'লিবিয়া মুদ্রার নাম কি',\n",
       "  'মালয়েশিয়ার মুদ্রার নাম কি',\n",
       "  'মালদ্বীপ এর মুদ্রার নাম কি',\n",
       "  'নরওয়ের মুদ্রার নাম কি',\n",
       "  'পাকিস্তানের মুদ্রার নাম কি',\n",
       "  'তাইওয়ানের মুদ্রার নাম কি',\n",
       "  'জিম্বাবুয়ের মুদ্রার নাম কি',\n",
       "  'মশাবাহিত রোগ কি',\n",
       "  'ফাইলেরিয়া/গোদ রোগ কি',\n",
       "  'পরজীবী রোগ কি',\n",
       "  'গবাদিপশু থেকে এ রোগে মানুষেও ছড়ায় কি রোগ',\n",
       "  'ব্যাকটেরিয়াজনিত কি রোগ',\n",
       "  'পানি দ্বারা ছড়ায় কি রোগ',\n",
       "  'বায়ু দ্বারা ছড়িয়ে কি রোগ',\n",
       "  'প্রাণী দ্বারা ছড়ায় কি রোগ',\n",
       "  'ভ্যারিসেলা জোস্টার নামক জীবাণুর মাধ্যমে ছড়ায় কি রোগ',\n",
       "  'ডায়াবেটিস কি',\n",
       "  \"'রিক্\\u200cসা' শব্দটি\",\n",
       "  'কোনটি হিন্দি শব্দ',\n",
       "  'খিদে কোন ধরনের শব্দ',\n",
       "  'নিচের কোনটি দেশী শব্দ',\n",
       "  'ক্যারাটে, জুতো, বিকশা কোন দেশী শব্দ',\n",
       "  '‘সিয়াম’ কোন ধরনের শব্দ',\n",
       "  'বাক্যের ক্ষুদ্রতম একক কোনটি',\n",
       "  '‘কাঁচি’ কোন ধরনের শব্দ',\n",
       "  \"'আলপিন' কোন ভাষার শব্দ\",\n",
       "  'কোনটি খাঁটি বাংলা শব্দ',\n",
       "  '‘হরতন’ কোন ভাষার শব্দ',\n",
       "  'প্রাচীনতম গাড়ির নাম কি',\n",
       "  'আধুনিক নাম কি বাহন',\n",
       "  'বর্তমানে দ্রুততম গাড়ির নাম কি',\n",
       "  'বর্তমানে জনপ্রিয় গাড়ির নাম কি',\n",
       "  'বর্তমানে বড় গাড়ির নাম কি',\n",
       "  'TOYOTA TACOMA কি',\n",
       "  'BMW কি',\n",
       "  'Air Bus কি',\n",
       "  'Caroler কি',\n",
       "  'বাংলাদেশের জাতীয় গাড়ির নাম কি',\n",
       "  'পৃথিবীর সবচেয়ে ছোট গাড়ি  নাম কি',\n",
       "  'রাষ্ট্রপতির মেয়াদকাল কত?',\n",
       "  'সংসদ এর মেয়াদকাল কত?',\n",
       "  'প্রধানমন্ত্রী এর মেয়াদকাল কত?',\n",
       "  'বিচারপতি এর মেয়াদকাল কত?',\n",
       "  'মন্ত্রী এর মেয়াদকাল কত?',\n",
       "  'চেয়ারম্যানের মেয়াদকাল কত?',\n",
       "  'নির্বাচন কমিশনার এর মেয়াদকাল কত?',\n",
       "  'একজন ব্যক্তি বাংলাদশের রাষ্ট্রপতি হতে পারবেন কত মেয়াদকাল?',\n",
       "  'সুপ্রীম কোর্টের বিচারপতিদের মেয়াদকাল কত ?',\n",
       "  'বাংলাদেশ সরকারী কর্ম কমিশনের চেয়ারম্যানের মেয়াদকাল কত?',\n",
       "  'কিভাবে বিজ্ঞানীরা ভূমিকম্প পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী দূরত্ব পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী ঘনত্ব পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী বিদ্যুত প্রবাহ  পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী গতি পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী তাড়িতচুম্বকীয় তরঙ্গ পরিমাপ করবেন',\n",
       "  'কিভাবে বিজ্ঞানী ভৌত রাশি পরিমাপ করবেন',\n",
       "  'বিজ্ঞানীরা উচ্চতা পরিমাপ করবেন কিভাবে',\n",
       "  'নবী মুহাম্মদ কি ধর্মের সর্বশেষ নবী',\n",
       "  'বাংলাদেশে সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'অস্ট্রেলিয়ার সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'ইরাকের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'জাপানের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'জাপানের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'লিবিয়া সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'মালয়েশিয়ার সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'মালদ্বীপ সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'নরওয়ের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'পাকিস্তানের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'যুক্তরাষ্ট্রের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'কানাডার সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'নরওয়ের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'ফ্রান্সের সর্বোচ্চ জনগণের ধর্ম কি',\n",
       "  'বাংলা বর্ণমালার প্রথম অক্ষর কি',\n",
       "  'বাংলা বর্ণমালার শেষ অক্ষর কি',\n",
       "  'বাংলা বর্ণমালার দ্বিতীয় অক্ষর কি',\n",
       "  'বাংলা বর্ণমালার মধ্যম অক্ষর কি',\n",
       "  'কম ব্যবহৃত  অক্ষর কি',\n",
       "  'অধিক ব্যবহৃত  অক্ষর কি',\n",
       "  'অক্ষর কি',\n",
       "  'যুক্তাক্ষর কি',\n",
       "  'অক্ষরমূল কি',\n",
       "  'সহ-অক্ষর কি',\n",
       "  'কম্পিউটার কি',\n",
       "  'বাতাসে ফরমালিন মাপার যন্ত্র নাম  কি',\n",
       "  'অতি উচ্চ তাপমাত্রা নির্ণয়ে যে যন্ত্র ব্যবহার করা হয়',\n",
       "  'বিমানের উচ্চতা পরিমাপের জন্য কি যন্ত্র ব্যবহৃত হয়',\n",
       "  'বায়ুতে আর্দ্রতা পরিমাপক যন্ত্রের নাম  কি',\n",
       "  'কি  উপকরণ ভর পরিমাপ ব্যবহার করা হয়',\n",
       "  'কি  উপকরণ ভূমিকম্প পরিমাপ ব্যবহার করা হয়',\n",
       "  'কি  উপকরণ ঘনত্ব পরিমাপ ব্যবহার করা হয়',\n",
       "  'কি  উপকরণ গতি পরিমাপ ব্যবহার করা হয়',\n",
       "  'কি  উপকরণ উচ্চতা পরিমাপ ব্যবহার করা হয়',\n",
       "  'একজন ব্যক্তির শরীরের মূল অংশ কি',\n",
       "  'একজন ব্যক্তির শরীরের গুরুত্বপূর্ণ অংশ কি',\n",
       "  'মানুষের শরীর, যেখানে প্রগণ্ডাস্থি হাড়',\n",
       "  'মানুষের মস্তিষ্কের সবচেয়ে বড় অংশ এর নাম কি',\n",
       "  'মানুষের শরীরের সবচেয়ে ছোট অঙ্গ কি',\n",
       "  'মানবদেহের সবচেয়ে ছোট অস্থি কোনটা',\n",
       "  'মানুষের শরীরের সবচেয়ে বড় অঙ্গ কি',\n",
       "  'মানবদেহে ত্বক বাইরে স্তর বলা হয় কি',\n",
       "  'মানবদেহে ত্বক ভিতরে স্তর বলা হয় কি',\n",
       "  'মানুষের শরীরের সর্ববৃহৎ গ্রন্থকি'],\n",
       " 'Label': ['ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY',\n",
       "  'ENTITY']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "65fde4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aafce6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa07e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-d2eb08c671f6e225\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-845bb527783794cf.arrow\n",
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b75883e7ec74cdc82e0f2be965f9d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9640957766056334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1f6482ce7042d087347a2e0a5b6d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.982088887042433}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381d571b592843bfb01f07214f206f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9810663930694502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b047f473cb64fef87c51c4a31bae841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9631994721764571}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../Bengali Pretraining/models/unigram/unigram-long-text and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arifa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5d6e62d8cc4f6b824133d403aa17aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9707524830914595}\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First make the kfold object\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.shuffle(seed=42)\n",
    "\n",
    "# Now make our splits based off of the labels. \n",
    "# We can use `np.zeros()` here since it only works off of indices, we really care about the labels\n",
    "splits = folds.split(np.zeros(tokenized_dataset.num_rows), tokenized_dataset[\"labels\"])\n",
    "\n",
    "# In this case I'm overriding the train/val/test\n",
    "for train_idxs, val_idxs in splits:\n",
    "    fold_dataset = DatasetDict({\n",
    "    \"train\":tokenized_dataset.select(train_idxs),\n",
    "    \"validation\":tokenized_dataset.select(val_idxs),\n",
    "    })\n",
    "    \n",
    "    from torch.utils.data import DataLoader\n",
    "    batch_size = 32\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        fold_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        fold_dataset[\"validation\"], batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    model =  AutoModelForSequenceClassification.from_pretrained(\"../Bengali Pretraining/models/unigram/unigram-long-text\", num_labels=num_labels)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "    #num_epochs = 3\n",
    "    num_epochs = 4\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    print(num_training_steps)\n",
    "    \n",
    "    #train model on each fold\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)    \n",
    "    \n",
    "    #validation on each fold\n",
    "    model.eval()\n",
    "    metric = evaluate.load(\"f1\")\n",
    "    \n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    \n",
    "    f1_score = metric.compute(average=\"macro\")\n",
    "    scores.append(f1_score['f1'])\n",
    "    print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "376f2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9640957766056334,\n",
       " 0.982088887042433,\n",
       " 0.9810663930694502,\n",
       " 0.9631994721764571,\n",
       " 0.9707524830914595]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7981f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722406023970865"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)  / len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

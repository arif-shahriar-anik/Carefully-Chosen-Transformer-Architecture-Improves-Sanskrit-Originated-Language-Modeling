{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb1c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig, CharacterBertModel, \\\n",
    "CharacterBertForPreTraining, CharacterBertConfig, CharacterBertTokenizer\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78843884",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = CharacterBertConfig.from_pretrained('../data/character-bert')\n",
    "model = CharacterBertForPreTraining(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d70b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual checkpoint file\n",
    "output_directory = \"model\"\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    output_directory, map_location=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221fa7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e977ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('character-bert-hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237d53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "# set_seed(42)\n",
    "set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8637df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=2)  # binary classification\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d435b347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpiece embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa1ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    \"E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005f2bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterCnn(\n",
       "  (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "  (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "  (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "  (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "  (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "  (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "  (_highways): Highway(\n",
       "    (_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpieces are replaced with a CharacterCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abd764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-60cb38e7639cbd07/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hate_speech_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\Hindi Hate Speech.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1c1826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Label'],\n",
       "    num_rows: 3654\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_speech_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecadf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = hate_speech_dataset[\"Label\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "822e429f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "HOF    1991\n",
       "NOT    1663\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aed49cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length = max(hate_speech_dataset['Text'].str.len())\n",
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf07240",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_speech_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c5be668",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterBertTokenizer(strip_accents=None, do_lower_case=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab199977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"Text\"], truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-da7e04c595b2fd23.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_dataset = hate_speech_dataset.map(tokenize_function, batched=True, remove_columns=[\"Text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8451fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3654\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f85001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e326bae26cda2748.arrow\n"
     ]
    }
   ],
   "source": [
    "temp = tokenized_dataset.filter(lambda x:x if tokenizer.unk_token_id in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82cc32d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00db1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\"HOF\":0, \"NOT\":1}\n",
    "    example['Label'] = mapping[example['Label']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a46142a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-16a09898a64377b1.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.map(assign_label)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"Label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fbdeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] तीन दिन से हथेली और लण्ड दोनों में खुजली हो रही थी. न पैसा मिला न चूत. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] जिन'नहीं वो निहायत ही मादरचोद किस्म की सुअर प्रजाति के लोग हैं, जिनका DNA तेरे जैसे लोगों से मिलता - जुलता है । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] सुंदरता सस्ती है. चरित्र महंगा है. घड़ी सस्ती है. समय महंगा है. शरीर सस्ता है. जीवन महंगा है. रिश्ता सस्ता है. लेकिन निभाना महंगा है. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] कभी चाल, कभी मकसद, कभी मंसूबे यार होते हैं. इस दौर के'नमस्ते'के भी मतलब हजार होते हैं. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] से याद आया, बरकी को काट खाओ, और कुत्ते से प्यार'दिखाओ '! कमाल करते हो पांडेजी! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] कैसे मुकदमा लङेगी फातिमा रन्ङी तू अपनी तन्हाई का हर हिन्दु लन्ङ गवाह है तेरी मक्का मदीना मे चुदाई का अल्ला झूठा मुल्ला झूठा झूठी सारी खुदाई चुत मिले अगर मुल्ली की तो कर दो जम के चुदाई वैसमोल ने किया कमाल । [SEP]'\n",
      "\n",
      "'>>> [CLS] भगवा'देश और क्रिकेट दोनों के लिए पनौती है! धत् । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] दिल्ली में मूर्ति तोड़ने की बात थी वहां तो अपनी'सेना'लेकर पहुंच गए थे! जहां एक'जिन्दा'आदमी को तोड़ दिया गया, वहां कब जाओगे? कोई नी ट्वीट कर दिए ना काम पूरा हुआ! [SEP]'\n",
      "\n",
      "'>>> [CLS] जी, खट्टी मीठी इलाहाबादी सियासत की याद दिलाता ये पोस्टर याद है आपको? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] इतने बकवास इंसान हो तुम! इस तस्वीर में एक बेटी भी है तुमने उसका तक मज़ाक बना डाला ऐश्वर्या का फैसला एकदम सही था । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_dataset[i] for i in range(10)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acefe412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': ['\\u200d तीन दिन से हथेली और लण्ड दोनों में खुजली हो रही थी . न पैसा मिला न चूत .',\n",
       "  \"जिन ' नहीं वो निहायत ही मादरचोद किस्म की सुअर प्रजाति के लोग हैं , जिनका DNA तेरे जैसे लोगों से मिलता - जुलता है ।\",\n",
       "  'सुंदरता सस्ती है . चरित्र महंगा है . घड़ी सस्ती है . समय महंगा है . शरीर सस्ता है . जीवन महंगा है . रिश्ता सस्ता है . लेकिन निभाना महंगा है .',\n",
       "  \"कभी चाल , कभी मकसद , कभी मंसूबे यार होते हैं . इस दौर के ' नमस्ते ' के भी मतलब हजार होते हैं .\",\n",
       "  \"से याद आया , बरकी को काट खाओ , और कुत्ते से प्यार ' दिखाओ ' ! कमाल करते हो पांडेजी !\",\n",
       "  'कैसे मुकदमा लङेगी फातिमा रन्ङी तू अपनी तन्हाई का हर हिन्दु लन्ङ गवाह है तेरी मक्का मदीना मे चुदाई का अल्ला झूठा मुल्ला झूठा झूठी सारी खुदाई चुत मिले अगर मुल्ली की तो कर दो जम के चुदाई वैसमोल ने किया कमाल ।',\n",
       "  \"भगवा ' देश और क्रिकेट दोनों के लिए पनौती है! धत् ।\",\n",
       "  \"दिल्ली में मूर्ति तोड़ने की बात थी वहां तो अपनी ' सेना ' लेकर पहुंच गए थे! जहां एक ' जिन्दा ' आदमी को तोड़ दिया गया , वहां कब जाओगे ? कोई नी ट्वीट कर दिए ना काम पूरा हुआ!\",\n",
       "  'जी , खट्टी मीठी इलाहाबादी सियासत की याद दिलाता ये पोस्टर याद है आपको ?',\n",
       "  'इतने बकवास इंसान हो तुम! इस तस्वीर में एक बेटी भी है तुमने उसका तक मज़ाक बना डाला ऐश्वर्या का फैसला एकदम सही था ।'],\n",
       " 'Label': ['HOF',\n",
       "  'HOF',\n",
       "  'NOT',\n",
       "  'NOT',\n",
       "  'NOT',\n",
       "  'HOF',\n",
       "  'HOF',\n",
       "  'HOF',\n",
       "  'NOT',\n",
       "  'HOF']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93559af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e6a71cf59bde7e9a.arrow and C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-6bb16ea0f9858540.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2923\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_dataset = tokenized_dataset.train_test_split(\n",
    "    train_size=0.8, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81a34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    downsampled_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    downsampled_dataset[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ccc01a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([32]),\n",
       " 'input_ids': torch.Size([32, 51, 50]),\n",
       " 'token_type_ids': torch.Size([32, 51]),\n",
       " 'attention_mask': torch.Size([32, 51])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72da652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7786, grad_fn=<NllLossBackward0>) torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d15803ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2d7af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "# num_epochs = 6\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e30025b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad4e89f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa53f6bb504049c1b3e14f8da2bdade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0bac603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "# results = f1_metric.compute(predictions=[0, 1], references=[0, 1], average=\"macro\")\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f387e04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8217022604157803}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_preds = []\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    y_preds.extend(predictions.cpu())\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute(average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3df4dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = downsampled_dataset[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68d4f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HOF       0.84      0.84      0.84       404\n",
      "         NOT       0.80      0.81      0.80       327\n",
      "\n",
      "    accuracy                           0.82       731\n",
      "   macro avg       0.82      0.82      0.82       731\n",
      "weighted avg       0.82      0.82      0.82       731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"HOF\", \"NOT\"]\n",
    "print(classification_report(y_true, y_preds,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18550ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aab9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-60cb38e7639cbd07\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-50946bf913459348.arrow\n",
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5bf66c00c74f18997aed2b3924b94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8287538728935238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dc99c440004c238a40a46f0eef0117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.809804823602166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab1c00b5cb647b2af76c8f4ea568f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8439028907152051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4e8b38f3204a109ee124a27053f947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8340708919174961}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a79bf8783d41baaaec4e8a20290e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8220450924923325}\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# First make the kfold object\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.shuffle(seed=30)\n",
    "\n",
    "# Now make our splits based off of the labels. \n",
    "# We can use `np.zeros()` here since it only works off of indices, we really care about the labels\n",
    "splits = folds.split(np.zeros(tokenized_dataset.num_rows), tokenized_dataset[\"labels\"])\n",
    "\n",
    "# In this case I'm overriding the train/val/test\n",
    "for train_idxs, val_idxs in splits:\n",
    "    fold_dataset = DatasetDict({\n",
    "    \"train\":tokenized_dataset.select(train_idxs),\n",
    "    \"validation\":tokenized_dataset.select(val_idxs),\n",
    "    })\n",
    "    \n",
    "    batch_size = 32\n",
    "    #batch_size = 16\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        fold_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        fold_dataset[\"validation\"], batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    #### LOADING BERT FOR CLASSIFICATION ####\n",
    "    config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)  # binary classification\n",
    "    model = BertForSequenceClassification(config=config)\n",
    "    \n",
    "    #### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "    character_bert_model = CharacterBertModel.from_pretrained(\\\n",
    "        \"E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\")\n",
    "    model.bert = character_bert_model\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    from transformers import get_scheduler\n",
    "\n",
    "    #num_epochs = 6\n",
    "    num_epochs = 3\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    print(num_training_steps)\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    f1_score = metric.compute(average=\"macro\")\n",
    "    scores.append(f1_score['f1'])\n",
    "    print(f1_score)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a38ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8287538728935238,\n",
       " 0.809804823602166,\n",
       " 0.8439028907152051,\n",
       " 0.8340708919174961,\n",
       " 0.8220450924923325]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc627aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277155143241446"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores) / len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

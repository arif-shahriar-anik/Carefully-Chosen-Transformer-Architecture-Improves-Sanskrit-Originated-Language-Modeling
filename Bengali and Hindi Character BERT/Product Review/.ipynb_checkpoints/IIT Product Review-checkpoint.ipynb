{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705888d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-a55165b542bdbb4e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "column_names=[\"labels\",\"text\"]\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-product-reviews\\hi\\hi-train.csv\", split=\"train\", column_names=column_names, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf443ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-cce6e8c355045cbb/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "val_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-product-reviews\\hi\\hi-valid.csv\", split=\"train\", column_names=[\"labels\",\"text\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b105db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-810710c2a6679d6b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-product-reviews\\hi\\hi-test.csv\", split=\"train\", column_names=[\"labels\",\"text\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971c96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "review_datasets = DatasetDict()\n",
    "review_datasets['train'] = train_dataset\n",
    "review_datasets['validation'] = val_dataset\n",
    "review_datasets['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6758cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 4182\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 523\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c44db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7386598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = train_dataset[\"labels\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fd91ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "positive    1826\n",
       "neutral     1789\n",
       "negative     567\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcd1891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length = max(train_dataset['text'].str.len())\n",
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9848d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698c93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "#set_seed(30)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef4cce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig, CharacterBertModel, CharacterBertTokenizer\n",
    "\n",
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)  # binary classification\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ebb300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpiece embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d824c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    \"E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f7c44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterCnn(\n",
       "  (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "  (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "  (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "  (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "  (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "  (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "  (_highways): Highway(\n",
       "    (_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpieces are replaced with a CharacterCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae60928",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterBertTokenizer(strip_accents=None, do_lower_case=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "894a223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_added_tokens = tokenizer.add_tokens([\"5\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7de20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b833509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "    #return tokenizer(example[\"text\"], truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38859875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-a55165b542bdbb4e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c205e3a2333a16a3.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-cce6e8c355045cbb\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-38febcb544c5b30f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-810710c2a6679d6b\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b45b299d2127d356.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_datasets = review_datasets.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c5c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4182\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 523\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5648aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-a55165b542bdbb4e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-13c4ee372134cb06.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-cce6e8c355045cbb\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b8d44b70d97003e5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-810710c2a6679d6b\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-a57ae5c74bbd5968.arrow\n"
     ]
    }
   ],
   "source": [
    "temp = tokenized_datasets.filter(lambda x:x if 0 in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fedfc6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc48ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in temp[\"train\"]:\n",
    "    print(tokenizer.decode(sample[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22f8c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "माइक्रोसॉफ्ट सरफेस 3 में 10.8 इंच की क्लियरटाइप फुल HD प्लस डिस्प्ले स्क्रीन है ।\n",
      "टैबलेट के दाहिनी उपरी तरफ वाल्यूम रॉकर के बगल में पॉवर ऑन ऑफ बटन है जबकि पोंर्ट्रेट मोड में पकड़ने परा नीचे मिनी HDMI एवं मिनी USB पोर्ट तथा चार्जर की जगह है ।\n",
      "इसके अलावा , कनेक्टिविटी के लिए यूएसबी 3.0 , यूएसबी 2.0 और HDMI पोर्ट दिए गए हैं ।\n",
      "ये टीवी एंड्रॉइड ऑपरेटिंग सिस्टम पर भी काम करेगी , जिसका मॉडल नंबर MI TV 2 40-Inch Full - HD है ।\n",
      "इसी जगह माइक्रोमैक्स के 4K टीवी HD से 8 गुना बेहतर क्वालिटी वाले 42 इंच स्क्रीन वाले टीवी की कीमत 39990 रुपए रखी गई है ।\n",
      "माइक्रोमैक्स के इस टेलीविजन का मॉडल 50B5000FHD LED स्पोर्ट्स के नाम से है ।\n",
      "टैबलेट के बाई तरफ 3.5 मिमी जैक , एचडीएमआई HDMI , मिनी यूएसवी , माइक्रो एसडी तथा चार्जिंग साकेट के सभी पोर्टस लगे है ।\n",
      "माइक्रोमैक्स फनबुक की एक और विशेषता है , इसमें लगा डूअल कोर 400 MHz का ग्राफिक प्रोसेसर जिससे इस डिवाइस पर फुल HD 1080p का वीडियो प्लेबैक की सुविधा भी है , पर एक बार फिर कम डिसप्ले रिजॉल्यूशन हाई डेफिनिशन कॉन्टेंट के मजे को खराब कर देता है जिससे यूजर मिनी HDMI पोर्ट का इस्तेमाल कर इस कॉनटेंट का मजा किसी अन्य बड़े स्कीन पर ले पाता है ।\n",
      "स्मार्टफोन्स की आम डाटा केबल में एक साइड USB होता है और दूसरी तरह HDMI है ।\n",
      "इसमें काई HDMI केबल नहीं है ।\n",
      "एडवांस सॉफ्टवेयर देने के साथ ये टीवी 2HDMI पोर्ट देता है ।\n",
      "चूंकि इस पैकेज में कोई HDMI एडॉप्टर शामिल नहीं है , तो यूजर को इसे अलग से ही खरीदना होगा ।\n",
      "डिवाइस का सकारात्मक विशेषताओं HDMI के इनपुट , कूलर , काम पर कोई आवाज नहीं , एक सोने मोड ढक्कन बंद करने या सत्ता बटन दबाने में प्रवेश करने की क्षमता शामिल है ।\n",
      "यह डोंगल HDMI पोर्ट के साथ आ रहा है , और यह सीधे आपके टीवी और प्रोजेक्टर से जुड़ सकता है ।\n",
      "इसी के साथ , स्मार्ट टीवी जो HD क्वालिटी का कंटेंट डिस्प्ले कर सके ।\n",
      "HP इलाइटबुक 1020 में 12.5 इंच फुल HD डिस्प्ले है , जो टचस्क्रीन भी है ।\n",
      "डिजिफलीप प्रो XT911 FHD रेसोलुशन और एक बड़े 8.9 इंच आईपीएस डिस्प्ले के साथ आता है ।\n",
      "इसकी स्क्रीन HD से दोगुना ज्यादा बेहतर क्वालिटी की है ।\n",
      "LED के पीछे स्पीकर्स और दूसरा सर्किट दिया है , इनमें ऑडियो पोर्ट , USB पोर्ट , 2 HDMI पोर्ट और VGA पोर्ट शामिल हैं ।\n",
      "4K डिस्प्ले क्वालिटी का मतलब है HD से 8 गुना बेहतर डिस्प्ले क्वालिटी वाला डिवाइस ।\n",
      "वो भी फुल HD स्क्रीन 1080 X 1920 Pixels के साथ है ।\n",
      "ग्राफिक्स कार्ड स्थापित और समर्पित स्मृति के 2GB के साथ इंटेल HD असतत NVIDIA GeForce जी. टी. 740M है , अच्छा कर रहे हैं ।\n",
      "यह इस नोटबुक लेनोवो एक छवि मॉडल के लिए अधिक है कि माना जाता है , हालांकि यह बहुत अच्छा ग्राफिक्स कार्ड के साथ सुसज्जित है , वीडियो प्रोसेसर चौथी पीढ़ी के इंटेल HD , राम के छह गीगाबाइट है ।\n",
      "ये HD टीवी 1366 * 768 पिक्सल के रेजोल्यूशन के साथ आता है ।\n",
      "इसके पुराने 49 इंच मॉडल में भी ये खासियत थीं जिसमें 4K UHD डिस्प्ले दिया गया था ।\n",
      "सिम स्लॉट नीचे की ओर है जबकि बाकी पोर्ट्स जिनमें चार्जिंग स्लॉट , माइक , मिनी यूएसबी , माइक्रो SD स्लॉट , HDMI पोर्ट और 3.5mm जैक टैबलेट के बायें कोने में हैं ।\n",
      "अगर इंटेक्स के इस टीवी की तुलना सैमसंग और सोनी ब्राविया मॉडल से की जाए तो 32 इंच की रेंज में HD टीवी के कई मॉडल भारतीय मार्केट में इसी रेंज में मिल जाएंगे ।\n",
      "ये अल्ट्रा HD यूजर्स को 8 मिलियन पिक्सल और फुल HD की 2 मिलियन पिक्सल क्वालिटी देती है ।\n",
      "ये LED 42 इंच 4K UHD है ।\n"
     ]
    }
   ],
   "source": [
    "for sample in review_datasets[\"train\"]:\n",
    "    if \"HD\" in sample[\"text\"]:\n",
    "        print(sample[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b77cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\"neutral\":0, \"positive\":1, \"negative\":2}\n",
    "    example['labels'] = mapping[example['labels']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f72f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-a55165b542bdbb4e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-15a48d2301b08239.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-cce6e8c355045cbb\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c38229a2ea2bdfdd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-810710c2a6679d6b\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-844bdf4ddd3bf1ab.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'validation': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'test': ['labels', 'input_ids', 'token_type_ids', 'attention_mask']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(assign_label)\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "399bf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] एंडराॅयड के मामले में यह थोड़ा पीछे है । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] यह एस्पेक्ट रेशो का ईश्यू है और हम आशा करते हैं कि यह आने वाले अपडेट में फिक्स कर दिया जाएगा । [SEP]'\n",
      "\n",
      "'>>> [CLS] लेकिन इस तरह के एक मॉडल के एक घर कंप्यूटर के लिए एक शानदार विकल्प हो सकता है । [SEP] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] गिर वन राष्ट्रीय उद्यान बाघ संरक्षित क्षेत्र है जो एशियाई बब्बर शेर के लिए विश्व प्रसिद्ध है । [SEP] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] और हां, इस फिल्म में हर किरदार भारद्वाज को भरद्वाज क्यों बुलाता है? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(5)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75eca670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['negative', 'neutral', 'positive', 'positive', 'neutral'],\n",
       " 'text': ['एंडराॅयड के मामले में यह थोड़ा पीछे है ।',\n",
       "  'यह एस्पेक्ट रेशो का ईश्यू है और हम आशा करते हैं कि यह आने वाले अपडेट में फिक्स कर दिया जाएगा ।',\n",
       "  'लेकिन इस तरह के एक मॉडल के एक घर कंप्यूटर के लिए एक शानदार विकल्प हो सकता है ।',\n",
       "  'गिर वन राष्ट्रीय उद्यान बाघ संरक्षित क्षेत्र है जो एशियाई बब्बर शेर के लिए विश्व प्रसिद्ध है ।',\n",
       "  'और हां , इस फिल्म में हर किरदार भारद्वाज को भरद्वाज क्यों बुलाता है ?']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ae60094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3f49e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([32]),\n",
       " 'input_ids': torch.Size([32, 35, 50]),\n",
       " 'token_type_ids': torch.Size([32, 35]),\n",
       " 'attention_mask': torch.Size([32, 35])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f39d52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1339) torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09c186ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_fun = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_result = metric_fun.compute(references=labels, predictions=predictions)\n",
    "    return {\n",
    "        \"accuracy\": metric_result[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cb53020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324b2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "# batch_size = 32\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/bert-unigram-hindi-classifier\",\n",
    "    report_to = None,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    #learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.02,\n",
    "    #warmup_ratio = 0.1,\n",
    "    #warmup_ratio = 0.05,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=4,\n",
    "    #num_train_epochs=5,\n",
    "    #push_to_hub=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d94821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# entire_train = concatenate_datasets([tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8085d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #train_dataset=entire_train,\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    #eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02236ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "trainer.remove_callback(transformers.integrations.TensorBoardCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20934010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.126199722290039,\n",
       " 'eval_accuracy': 0.30975143403441685,\n",
       " 'eval_runtime': 3.8778,\n",
       " 'eval_samples_per_second': 134.871,\n",
       " 'eval_steps_per_second': 8.51}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7440206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4182\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1048' max='1048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1048/1048 02:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.652592</td>\n",
       "      <td>0.715105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.622668</td>\n",
       "      <td>0.743786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.691729</td>\n",
       "      <td>0.747610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.778569</td>\n",
       "      <td>0.749522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1048, training_loss=0.4679371405193824, metrics={'train_runtime': 124.7303, 'train_samples_per_second': 134.113, 'train_steps_per_second': 8.402, 'total_flos': 2.100212315721e+16, 'train_loss': 0.4679371405193824, 'epoch': 4.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f026e2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7257173657417297,\n",
       " 'eval_accuracy': 0.7609942638623327,\n",
       " 'eval_runtime': 1.3886,\n",
       " 'eval_samples_per_second': 376.628,\n",
       " 'eval_steps_per_second': 23.764,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "036d1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d323c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"models/bert-unigram-hindi-classifier\")\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddefcfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 523\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7785689234733582,\n",
       " 'eval_accuracy': 0.7495219885277247,\n",
       " 'eval_runtime': 1.4621,\n",
       " 'eval_samples_per_second': 357.713,\n",
       " 'eval_steps_per_second': 22.571,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

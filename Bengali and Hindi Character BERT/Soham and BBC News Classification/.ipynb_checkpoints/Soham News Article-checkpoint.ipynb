{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705888d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-288983945b809be3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\soham-articles\\\\bn\\\\bn-train.csv\", column_names=[\"labels\",\"text\"], split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7484c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-934cec49a13b53ff/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\soham-articles\\\\bn\\\\bn-valid.csv\", column_names=[\"labels\",\"text\"], split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b105db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/arifa/.cache/huggingface/datasets/csv/default-04dc69dd625404f0/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\soham-articles\\\\bn\\\\bn-test.csv\", column_names=[\"labels\",\"text\"], split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971c96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "news_datasets = DatasetDict()\n",
    "news_datasets['train'] = train_dataset\n",
    "news_datasets['test'] = test_dataset\n",
    "news_datasets['validation'] = valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6758cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 11284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 1411\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 1411\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c44db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7386598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = train_dataset[\"labels\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fd91ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "kolkata          4603\n",
       "state            2245\n",
       "national         1435\n",
       "sports           1289\n",
       "entertainment    1186\n",
       "international     526\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcd1891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length = max(train_dataset['text'].str.len())\n",
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3c3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train_dataset['text'].str.split().apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee37ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "count.index = count.index.astype(str) + ' words:'\n",
    "count.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6913c08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "100 words:     28\n",
       "1002 words:     2\n",
       "101 words:     20\n",
       "1013 words:     1\n",
       "1017 words:     1\n",
       "               ..\n",
       "98 words:      25\n",
       "987 words:      1\n",
       "99 words:      19\n",
       "992 words:      1\n",
       "999 words:      1\n",
       "Name: count, Length: 771, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9848d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698c93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(30)\n",
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd3efaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig, CharacterBertModel, CharacterBertTokenizer\n",
    "\n",
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)  # binary classification\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a993c30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpiece embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4302d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Question Classification\\character-bert were not used when initializing CharacterBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    \"E:\\Documents\\Character Bert\\Question Classification\\character-bert\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f6ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterCnn(\n",
       "  (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "  (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "  (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "  (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "  (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "  (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "  (_highways): Highway(\n",
       "    (_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpieces are replaced with a CharacterCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a454b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Load the actual checkpoint file\n",
    "# checkpoint = torch.load(\n",
    "#     output_directory, map_location=\"cpu\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed1cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(checkpoint['model'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a701fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterBertTokenizer(strip_accents=None, do_lower_case=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b833509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38859875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-288983945b809be3\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e98e8e56455d1237.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-04dc69dd625404f0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b118f805ce8ac4b0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-934cec49a13b53ff\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e8a6e6f18f150f3b.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_datasets = news_datasets.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90c5c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 11284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1411\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1411\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5648aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = tokenized_datasets.filter(lambda x:x if tokenizer.unk_token_id in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fedfc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbc48ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in temp[\"train\"]:\n",
    "#     print(tokenizer.decode(sample[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e711f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"kolkata\":4603,\n",
    "# \"state\":2245,\n",
    "# \"national\":1435,\n",
    "# \"sports\":1289,\n",
    "# \"entertainment\":1186,\n",
    "# \"international\":526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b77cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\n",
    "        \"kolkata\":0,\n",
    "        \"state\":1,\n",
    "        \"national\":2,\n",
    "        \"sports\":3,\n",
    "        \"entertainment\":4,\n",
    "        \"international\":5\n",
    "    }\n",
    "    example['labels'] = mapping[example['labels']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f72f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-288983945b809be3\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-07499d1639bcd994.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-04dc69dd625404f0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-8fd5c59463e59219.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-934cec49a13b53ff\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-ac1979357c97e3dd.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'test': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'validation': ['labels', 'input_ids', 'token_type_ids', 'attention_mask']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(assign_label)\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "399bf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] প্রজাপতি প্রজাপতি আমার ইচ্ছে হয়ে, বনে বনে ঘাসে ঘাসে ওড়ে আর ফেরে... সেই সুর যা ফিরিয়ে দেয় শৈশবের সুগন্ধ । সবিতা চৌধুরী । যাঁর কণ্ঠ অপূর্ব সব গানগুচ্ছ উপহার দিয়েছে সব প্রজন্মের গানপ্রেমীদের । দুরারোগ্য কর্কটরোগে আক্রান্ত সেদিনের সবিতা । গত কয়েক বছর ধরে নিরন্তর লড়াইয়ের পর এখন প্রহর গুনছেন । যেকোনও দিনই আসতে পারে সেই ভয়ঙ্কর দিনটি । এখন তাঁর বড় মেয়ে অন্তরা চৌধুরীর কাছেই আছেন তিনি । রুবি হাসপাতালের খুব কাছেই বড় মেয়ের কাছেই কাটাতে চান জীবনের শেষ কয়েকটি দিন । আজই এবেলা. ইন কে জানালেন অন্তরা । স্বামী সলিল চৌধুরীর অনুরোধেই প্রথম অ্যালবামে গাওয়া গান মরি হায় গো হায় । সবিতার কণ্ঠস্বরের জাদুতে সেই গান শাশ্বত হয়ে আছে । এখন এই আনন্দের শহরে একলা শুয়ে সবিতা । সুরের [SEP]'\n",
      "\n",
      "'>>> [CLS] দীর্ঘ সাত মাসের প্রতীক্ষার পর সোমবার সকালে এসে পৌঁছল কলকাতা মেট্রো রেলের নতুন এসি রেক । গত ডিসেম্বরে ওই রেকটি এসে পৌঁছনোর কথা থাকলেও একাধিক কারণে রেক পেতে অনেকটা দেরি হল বলে মেট্রো সূত্রের খবর । চেন্নাইয়ের ইন্টিগ্রাল কোচ ফ্যাক্টরিকে ( আইসিএফ ) দু ’ টি এসি রেকের বরাত দেওয়া হয়েছিল । তার মধ্যে প্রথম রেকটি এদিন এসে পৌঁছেছে । দ্বিতীয় রেকটি পৌঁছনোর কথা অগস্টের তৃতীয় সপ্তাহে । এখনকার এসি রেকগুলির তুলনায় নতুন এসি রেক প্রযুক্তিগতভাবে অনেকটাই এগিয়ে বলে । জানা গিয়েছে, চলতি বছরের শেষে চিনের ডালিয়ান থেকে মেট্রোর রেক আসা শুরু হবে । সম্পূর্ণ দেশীয় প্রযুক্তিতে তৈরি আইসিএফের রেকগুলি যাতে কোনওভাবে ওই রেকের তুলনায় পিছিয়ে না থাকে তা নিশ্চিত করার চেষ্টা হয়েছে । নতুন রেকের মোটর - সহ মূল অংশ ( প্রপালসন ) তৈরি [SEP]'\n",
      "\n",
      "'>>> [CLS] দিঘার হোটেল থেকে উদ্ধার হল যুবক - যুবতীর ঝুলন্ত দেহ । শুক্রবার সকালে নিউ দিঘার একটি হোটেল থেকে ওই যুগলের দেহ উদ্ধার হয় । মৃতদের দাম গোপাল সরকার ও অতসি সরকার । হোটেল কর্তৃপক্ষের কাছে তাঁরা এই নাম দিয়েই রুম বুক করেছিলেন বলে জানা গিয়েছে । এই বিষয়ে অন্যান্য খবর ফুটফুটে বাচ্চাটি কার! দিঘার সৈকতে শিশুর কান্না, জল্পনা চাপা দিল সমুদ্রের গর্জন দিঘায় মারাত্মক অভিযোগ! মহিলা পর্যটককে প্রায় বিবস্ত্র করে হেনস্থা জানা গিয়েছে, স্বামী - স্ত্রীর পরিচয় দিয়ে ওই যুগল গত ১৫ তারিখ হোটেলে ওঠেন । হোটেলের রেজিস্টারে হুগলির তারকেশ্বরের মুক্তারপুরের গ্রামের বাসিন্দা বলেন তাঁরা । শুক্রবারই তাঁদের ফিরে যাওয়ার কথা ছিল । এদিন সকালে রুমের মধ্যে থেকে যুবক - যুবতীর কোনও সাড়াশব্দ না পাওয়ায় সন্দেহ হয় হোটেলকর্মীদের মধ্যে । পরে দরজা [SEP]'\n",
      "\n",
      "'>>> [CLS] কিছুদিন আগেই রাজ্যের গাইড বনে গিয়েছিলেন চেতেশ্বর পূজারা । রাজকোটে ভারত - ওয়েস্ট ইন্ডিজ প্রথম টেস্ট চলাকালীনই পূজারাকে দেখা গিয়েছিল নয়া অবতারে । এবার সেই পথেই হাঁটলেন মহম্মদ সিরাজ । এই বিষয়ে অন্যান্য খবর কুম্বলের গুগলিতে ‘ বোল্ড ’ সোহিনী, মাঝ আকাশে মন জিতলেন ক্রিকেটার হায়দরাবাদে দ্বিতীয় টেস্ট শুরু হচ্ছে শুক্রবারেই । সেই টেস্ট শুরুর আগেই হায়দরাবাদের ট্যুর গাইড হয়ে গেলেন সিরাজ । হায়দরাবাদের দ্রষ্টব্য কী? সিরাজ জানাচ্ছেন, চারমিনারে যেতেই হবে । ওখান থেকে চাঁদ দেখার অভিজ্ঞতা দুর্ধর্ষ! পাশাপাশি তিনি নেকলেস রোডেও ঘুরে আসার পরামর্শ দিয়েছেন ভ্রমণার্থীদের । রিল্যাক্স করার জন্য নাকি নেকলেস রোড আদর্শ । ট্যুরিস্টদের হায়দরাবাদের বিখ্যাত বিরিয়ানি চেখে দেওয়ার কথা বলেছেন তারকা পেসার । সিরাজের এই ‘ গাইড ’ হওয়ার ভিডিও বিসিসিআই শেয়ার করেছেন নিজেদের ফেসবুক পেজে । ইতিমধ্যেই [SEP]'\n",
      "\n",
      "'>>> [CLS] মারুতির কারখানায় হামলা এবং ম্যানেজারকে পুড়িয়ে মারার ঘটনায় ৩১ জনকে দোষী সাব্যস্ত করল হরিয়ানার আদালত । দোষীরা প্রত্যেকেই মানেসরের মারুতি - সুজুকি প্ল্যান্টের কর্মী । দিল্লির প্রায় ৪০ কিলোমিটার দক্ষিণে অবস্থিত ওই প্ল্যান্টে ২০১২ সালে এক দল শ্রমিকের হাতে আক্রান্ত হয়েছিলেন সংস্থার উচ্চপদস্থ কর্তারা । কনফারেন্স রুমের মধ্যে হিউম্যান রিসোর্স ম্যানেজার অবনীশ কুমার দেবের গায়ে আগুন ধরিয়ে দেওয়া হয়েছিল । সেখানেই মৃত্যু হয়েছিল তাঁর । দীর্ঘ ক্ষণ ধরে চলতে থাকা তাণ্ডবে ম্যানেজমেন্টের অন্তত ৫০ জন কর্তা জখম হয়েছিলেন, আক্রান্ত হয়েছিল পুলিশও । ঘটনার বছর চারেক পর গুরুগ্রামের আদালত মামলাটির রায় ঘোষণা করল । মারুতি সংস্থা প্রতি বছর যে পরিমাণ গাড়ি তৈরি করে, তার এক তৃতীয়াংশই তৈরি হয় মানেসরের প্ল্যান্টে । ২০১২ সালের বেনজির গোলমালের পর সেই মানেসর প্ল্যান্ট মাস খানেকের জন্য বন্ধ করে দিয়েছিল [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(5)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75eca670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['entertainment', 'state', 'state', 'sports', 'national'],\n",
       " 'text': ['প্রজাপতি প্রজাপতি আমার ইচ্ছে হয়ে, বনে বনে ঘাসে ঘাসে ওড়ে আর ফেরে...\\nসেই সুর যা ফিরিয়ে দেয় শৈশবের সুগন্ধ। সবিতা চৌধুরী। যাঁর কণ্ঠ অপূর্ব সব গানগুচ্ছ উপহার দিয়েছে সব প্রজন্মের গানপ্রেমীদের। দুরারোগ্য কর্কটরোগে আক্রান্ত সেদিনের সবিতা। গত কয়েক বছর ধরে নিরন্তর লড়াইয়ের পর এখন প্রহর গুনছেন । যেকোনও দিনই আসতে পারে সেই ভয়ঙ্কর দিনটি।\\nএখন তাঁর বড় মেয়ে অন্তরা চৌধুরীর কাছেই আছেন তিনি। রুবি হাসপাতালের খুব কাছেই বড় মেয়ের কাছেই কাটাতে চান জীবনের শেষ কয়েকটি দিন। আজই এবেলা.ইন কে জানালেন অন্তরা।\\nস্বামী সলিল চৌধুরীর অনুরোধেই প্রথম অ্যালবামে গাওয়া গান মরি হায় গো হায়। সবিতার কণ্ঠস্বরের জাদুতে সেই গান শাশ্বত হয়ে আছে।\\xa0\\nএখন এই আনন্দের শহরে একলা শুয়ে সবিতা। সুরের সেই ঝর-ঝর-ঝরণা যে আজ নিরুচ্চার',\n",
       "  'দীর্ঘ সাত মাসের প্রতীক্ষার পর সোমবার সকালে এসে পৌঁছল কলকাতা মেট্রো রেলের নতুন এসি রেক। গত ডিসেম্বরে ওই রেকটি এসে পৌঁছনোর কথা থাকলেও একাধিক কারণে রেক পেতে অনেকটা দেরি হল বলে মেট্রো সূত্রের খবর।\\xa0\\nচেন্নাইয়ের ইন্টিগ্রাল কোচ ফ্যাক্টরিকে (আইসিএফ) দু’টি এসি রেকের বরাত দেওয়া হয়েছিল। তার মধ্যে প্রথম রেকটি এদিন এসে পৌঁছেছে। দ্বিতীয় রেকটি পৌঁছনোর কথা অগস্টের তৃতীয় সপ্তাহে। এখনকার এসি রেকগুলির তুলনায় নতুন এসি রেক প্রযুক্তিগতভাবে অনেকটাই এগিয়ে বলে। জানা গিয়েছে, চলতি বছরের শেষে চিনের ডালিয়ান থেকে মেট্রোর রেক আসা শুরু হবে। সম্পূর্ণ দেশীয় প্রযুক্তিতে তৈরি আইসিএফের রেকগুলি যাতে কোনওভাবে ওই রেকের তুলনায় পিছিয়ে না থাকে তা নিশ্চিত করার চেষ্টা হয়েছে।\\xa0\\n\\xa0নতুন রেকের মোটর-সহ মূল অংশ (প্রপালসন) তৈরি করেছে হায়দরাবাদের একটি সংস্থা। রেকের বাইরের কাঠামো তৈরি করেছে আইসিএফ। নতুন রেকগুলিতে এসি, ভেস্টিবিউল,সাসপেনশন, ব্রেকিং সিস্টেম সব কিছুতেই ব্যাপক বদল আনা হয়েছে।\\nনতুন রেকে ভেস্টিবিউলের প্রস্থ এক ধাক্কায় ৭০০ থেকে বেড়ে হচ্ছে ১৪০০ মিলিমিটার। ফলে দু’টি কামরার মধ্যে যাতায়াত অনেকটাই সহজসাধ্য হবে। চলতি এসি রেকে দরজার দু’প্রান্তের মাঝের ব্যবধান ১২১০ মিলিমিটার। ওই ব্যবধান বেড়ে হচ্ছে ১৪০০ মিলিমিটার। এসি’র ড্রেনেজ পাইপের অবস্থানও বদলেছে। চলার সময় রেক ঠান্ডা না হওয়ার সমস্যা ঠেকাতে রুফ মাউন্টিং ইউনিটের প্রযুক্তিতে বদল আনা হয়েছে। ঝাঁকুনি কমাতে স্টিল কয়েলের বদলে রাবার স্প্রিং সাসপেনশন ব্যবহার করা হচ্ছে নতুন রেকে। আমূল বদল আনা হয়েছে ব্রেকিং সিস্টেমে। নতুন রেকে স্টেপলেস রিজেনারেটিভ ব্রেক থাকছে। এতে অনেকটাই বিদ্যুৎ সাশ্রয় হবে।\\xa0\\nমেট্রোর এক আধিকারিক জানান, “থার্ড রেলের সঙ্গে সংযোগকারী অংশ বসানো ছাড়াও অবশিষ্ট কাজ করতে ৪৫ দিন লাগতে পারে। তারপর ওই রেক চলার উপযুক্ত হবে।”',\n",
       "  'দিঘার হোটেল থেকে উদ্ধার হল যুবক-যুবতীর ঝুলন্ত দেহ। শুক্রবার সকালে নিউ দিঘার একটি হোটেল থেকে ওই যুগলের দেহ উদ্ধার হয়। মৃতদের দাম গোপাল সরকার ও অতসি সরকার। হোটেল কর্তৃপক্ষের কাছে তাঁরা এই নাম দিয়েই রুম বুক করেছিলেন বলে জানা গিয়েছে।\\n\\nএই বিষয়ে অন্যান্য খবর\\n\\nফুটফুটে বাচ্চাটি কার! দিঘার সৈকতে শিশুর কান্না, জল্পনা চাপা দিল সমুদ্রের গর্জন\\nদিঘায় মারাত্মক অভিযোগ! মহিলা পর্যটককে প্রায় বিবস্ত্র করে হেনস্থা\\n\\n\\nজানা গিয়েছে, স্বামী-স্ত্রীর পরিচয় দিয়ে ওই যুগল গত ১৫ তারিখ হোটেলে ওঠেন। হোটেলের রেজিস্টারে হুগলির তারকেশ্বরের মুক্তারপুরের গ্রামের বাসিন্দা বলেন তাঁরা। শুক্রবারই তাঁদের ফিরে যাওয়ার কথা ছিল।\\xa0\\nএদিন সকালে রুমের মধ্যে থেকে যুবক-যুবতীর কোনও সাড়াশব্দ না পাওয়ায় সন্দেহ হয় হোটেলকর্মীদের মধ্যে। পরে দরজা ভাঙতেই তাঁদের ঝুলন্ত দেহ দেখতে পান হোটেলকর্মীরা। পরে পুলিশ এসে দেহদুটি উদ্ধার করে ময়নাতদন্তের জন্য পাঠায়।\\nপুলিশের প্রাথমিক ধারণা প্রেমঘটিত কারণের জেরে আত্মহত্যা করেছেন ওই যুগল। ঘটনার তদন্তে নেমেছে দিঘা থানার পুলিশ।',\n",
       "  \"কিছুদিন আগেই রাজ্যের গাইড বনে গিয়েছিলেন চেতেশ্বর পূজারা। রাজকোটে ভারত-ওয়েস্ট ইন্ডিজ প্রথম টেস্ট চলাকালীনই পূজারাকে দেখা গিয়েছিল নয়া অবতারে। এবার সেই পথেই হাঁটলেন মহম্মদ সিরাজ।\\n\\nএই বিষয়ে অন্যান্য খবর\\n\\nকুম্বলের গুগলিতে ‘বোল্ড’ সোহিনী, মাঝ আকাশে মন জিতলেন ক্রিকেটার\\n\\n\\nহায়দরাবাদে দ্বিতীয় টেস্ট শুরু হচ্ছে শুক্রবারেই। সেই টেস্ট শুরুর আগেই হায়দরাবাদের ট্যুর গাইড হয়ে গেলেন সিরাজ। হায়দরাবাদের দ্রষ্টব্য কী? সিরাজ জানাচ্ছেন, চারমিনারে যেতেই হবে। ওখান থেকে চাঁদ দেখার অভিজ্ঞতা দুর্ধর্ষ! পাশাপাশি তিনি নেকলেস রোডেও ঘুরে আসার পরামর্শ দিয়েছেন ভ্রমণার্থীদের। রিল্যাক্স করার জন্য নাকি নেকলেস রোড আদর্শ।\\nট্যুরিস্টদের হায়দরাবাদের বিখ্যাত বিরিয়ানি চেখে দেওয়ার কথা বলেছেন তারকা পেসার। সিরাজের এই ‘গাইড’ হওয়ার ভিডিও বিসিসিআই শেয়ার করেছেন নিজেদের ফেসবুক পেজে। ইতিমধ্যেই যা ভাইরাল। ভিডিওতে সিরাজকে দেখা যাচ্ছে, স্থানীয় উচ্চারণে কথা বলতে।\\n\\nLocal boy Siraj's top 3 things to do in Hyderabad 😎\\n\\nWhat to do when in Hyderabad? Mohammed Siraj lists his top 3 not-to-be-missed things from his home land. P.S In total Hyderabadi style 🤙 - by @28anand\\n\\nMUST WATCH ▶️ https://t.co/ceSRC2lMHK #INDvWI pic.twitter.com/toeN6j70pR\\n— BCCI (@BCCI) October 11, 2018\\n\\nভিডিওতে সিরাজ একজন ‘প্রাউড হায়দরাবাদি’। ঘরের ছেলের এমন বক্তব্যের পরে হায়দরাবাদের দর্শকরা কতটা মাঠ ভরায় সেটাই এখন দেখার।\",\n",
       "  'মারুতির কারখানায় হামলা এবং ম্যানেজারকে পুড়িয়ে মারার ঘটনায় ৩১ জনকে দোষী সাব্যস্ত করল হরিয়ানার আদালত। দোষীরা প্রত্যেকেই মানেসরের মারুতি-সুজুকি প্ল্যান্টের কর্মী। দিল্লির প্রায় ৪০ কিলোমিটার দক্ষিণে অবস্থিত ওই প্ল্যান্টে ২০১২ সালে এক দল শ্রমিকের হাতে আক্রান্ত হয়েছিলেন সংস্থার উচ্চপদস্থ কর্তারা। কনফারেন্স রুমের মধ্যে হিউম্যান রিসোর্স ম্যানেজার অবনীশ কুমার দেবের গায়ে আগুন ধরিয়ে দেওয়া হয়েছিল। সেখানেই মৃত্যু হয়েছিল তাঁর। দীর্ঘ ক্ষণ ধরে চলতে থাকা তাণ্ডবে ম্যানেজমেন্টের অন্তত ৫০ জন কর্তা জখম হয়েছিলেন, আক্রান্ত হয়েছিল পুলিশও। ঘটনার বছর চারেক পর গুরুগ্রামের আদালত মামলাটির রায় ঘোষণা করল। মারুতি সংস্থা প্রতি বছর যে পরিমাণ গাড়ি তৈরি করে, তার এক তৃতীয়াংশই তৈরি হয় মানেসরের প্ল্যান্টে। ২০১২ সালের বেনজির গোলমালের পর সেই মানেসর প্ল্যান্ট মাস খানেকের জন্য বন্ধ করে দিয়েছিল মারুতি কর্তৃপক্ষ। শ্রমিকদের বিরুদ্ধে শৃঙ্খলাভঙ্গের অভিযোগকে ঘিরে গোলমালের সূত্রপাত হয়েছিল। ম্যানেজমেন্টের অভিযোগ ছিল, যে কোনও আলোচনার সময়েই শ্রমিক ইউনিয়ন সংস্থার পদস্থ কর্তাদের আক্রমণ করত। পরিস্থিতি শৃঙ্খলাভঙ্গের পর্যায়ে যাচ্ছিল বলে ম্যানেজমেন্ট মনে করছিল। তাই কঠোর পদক্ষেপের কথা ভাবা হয়েছিল। সে সব নিয়ে দীর্ঘ দিন ধরে মানেসর প্ল্যান্টে শ্রমিক অসন্তোষ চলছিল। সেই অসন্তোষই শেষ দিনে তাণ্ডবের চেহারা নেয়। লোহার রড এবং নির্মিয়মান গাড়ির দরজার প্যানেল নিয়ে হামলা চালান শ্রমিকরা। হিউম্যান রিসোর্স ম্যানেজারকে পুড়িয়ে মারা হয়। সুপারভাইজার এবং অন্য পদস্থ করাদের খুঁজে বার করে হামলা চালানো হয়। গোটা কারখানা চত্বর জুড়ে ভাঙচুর চলে, জায়গায় জায়গায় আগুনও গালিয়ে দেওয়া হয়। ১২০০ পুলিশ পাঠিয়ে কারখানা নিয়ন্ত্রণে এনেছিল প্রশাসন। তবে ৯ জন পুলিশ কর্তাও সংঘর্ষে জখম হয়েছিলেন। ম্যানেজমেন্টের য়ে ৫০ জন কর্তাকে জখম অবস্থায় উদ্ধার করা হয়েছিল, তাঁদের অধিকাংশই রক্তাক্ত ছিলেন, অনেকেই অচেতনও ছিলেন। শ্রমিকদের অবশ্য দাবি ছিল, ম্যানেজমেন্টের বাড়াটে বাউন্সাররা প্ল্যান্টের সমস্ত দরজা বন্ধ করে দিয়ে শ্রমিকদের উপর হামলা চালিয়েছিল। সেখান থেকেই নাকি গোলমালের সূত্রপাত। কারখানা চত্বরের বিভিন্ন সিসিটিভির ফুটেজ খতিয়ে দেখে সন্দেহভাজনদের গ্রেফতার করে পুলিশ। বহু শ্রমিককে জেরা করা হয়। প্রায় ১৫০ জনকে অভিযুক্ত করা হয়। শুক্রবার গুরুগ্রামের আদালত অভিযুক্তদের মধ্যে ৩১ জনকে দোষী সাব্যস্ত করেছে। তাঁদের বিরুদ্ধে ম্যানেজমেন্টের উপর হামলা, সম্পত্তি নষ্ট এবং ম্যানেজারকে খুনের অভিযোগ প্রমাণিত হয়েছে বলে আদালতটি জানিয়েছে। সাজা ঘোষণা হওয়া এখনও বাকি।']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ae60094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3f49e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([32]),\n",
       " 'input_ids': torch.Size([32, 128, 50]),\n",
       " 'token_type_ids': torch.Size([32, 128]),\n",
       " 'attention_mask': torch.Size([32, 128])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f39d52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8421) torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09c186ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_fun = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_result = metric_fun.compute(references=labels, predictions=predictions)\n",
    "    return {\n",
    "        \"accuracy\": metric_result[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb53020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "324b2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/bert-unigram-bengali-classifier\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to = None,\n",
    "    logging_dir= None,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #learning_rate=2e-5,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.02,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    #num_train_epochs=6,\n",
    "    #push_to_hub=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d94821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# entire_train = concatenate_datasets([tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8085d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #train_dataset=entire_train,\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ef743fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "trainer.remove_callback(transformers.integrations.TensorBoardCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f026e2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 02:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8308228254318237,\n",
       " 'eval_accuracy': 0.1261516654854713,\n",
       " 'eval_runtime': 10.9291,\n",
       " 'eval_samples_per_second': 129.104,\n",
       " 'eval_steps_per_second': 4.117}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7440206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11284\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1765' max='1765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1765/1765 13:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.829908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>0.423985</td>\n",
       "      <td>0.866052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.350479</td>\n",
       "      <td>0.887314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.361164</td>\n",
       "      <td>0.890149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.375412</td>\n",
       "      <td>0.896527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1765, training_loss=0.32843787649873296, metrics={'train_runtime': 824.6313, 'train_samples_per_second': 68.418, 'train_steps_per_second': 2.14, 'total_flos': 2.25781730044416e+17, 'train_loss': 0.32843787649873296, 'epoch': 5.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddefcfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1411\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29614242911338806,\n",
       " 'eval_accuracy': 0.9192062367115521,\n",
       " 'eval_runtime': 14.0471,\n",
       " 'eval_samples_per_second': 100.448,\n",
       " 'eval_steps_per_second': 3.204,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "657bd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"best-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d8e8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        'model': model.state_dict(),\n",
    "    },\n",
    "    output_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "26a9b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in models/bert-unigram-bengali-classifier\\config.json\n",
      "Model weights saved in models/bert-unigram-bengali-classifier\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"models/bert-unigram-bengali-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "036d1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0dd917c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/bert-unigram-bengali-classifier\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file models/bert-unigram-bengali-classifier\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at models/bert-unigram-bengali-classifier were not used when initializing BertForSequenceClassification: ['bert.embeddings.word_embeddings.char_conv_4.bias', 'bert.embeddings.word_embeddings.char_conv_0.weight', 'bert.embeddings.word_embeddings._highways._layers.1.bias', 'bert.embeddings.word_embeddings.char_conv_1.weight', 'bert.embeddings.word_embeddings._highways._layers.0.bias', 'bert.embeddings.word_embeddings.char_conv_3.bias', 'bert.embeddings.word_embeddings.char_conv_6.weight', 'bert.embeddings.word_embeddings.char_conv_2.bias', 'bert.embeddings.word_embeddings._projection.weight', 'bert.embeddings.word_embeddings._highways._layers.0.weight', 'bert.embeddings.word_embeddings.char_conv_6.bias', 'bert.embeddings.word_embeddings.char_conv_3.weight', 'bert.embeddings.word_embeddings.char_conv_0.bias', 'bert.embeddings.word_embeddings._char_embedding_weights', 'bert.embeddings.word_embeddings._projection.bias', 'bert.embeddings.word_embeddings.char_conv_1.bias', 'bert.embeddings.word_embeddings.char_conv_5.weight', 'bert.embeddings.word_embeddings.char_conv_2.weight', 'bert.embeddings.word_embeddings.char_conv_4.weight', 'bert.embeddings.word_embeddings._highways._layers.1.weight', 'bert.embeddings.word_embeddings.char_conv_5.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at models/bert-unigram-bengali-classifier and are newly initialized: ['bert.embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"models/bert-unigram-bengali-classifier\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a806f075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/bert-unigram-bengali-classifier\\config.json\n",
      "You are using a model of type bert to instantiate a model of type character_bert. This is not supported for all configurations of models and can yield errors.\n",
      "Model config CharacterBertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"character_embeddings_dim\": 16,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cnn_activation\": \"relu\",\n",
      "  \"cnn_filters\": [\n",
      "    [\n",
      "      1,\n",
      "      32\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      32\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      64\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      128\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      256\n",
      "    ],\n",
      "    [\n",
      "      6,\n",
      "      512\n",
      "    ],\n",
      "    [\n",
      "      7,\n",
      "      1024\n",
      "    ]\n",
      "  ],\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_word_length\": 50,\n",
      "  \"mlm_vocab_size\": 100000,\n",
      "  \"model_type\": \"character_bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_highway_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file models/bert-unigram-bengali-classifier\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at models/bert-unigram-bengali-classifier were not used when initializing CharacterBertModel: ['bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.embeddings.word_embeddings._highways._layers.0.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.embeddings.position_ids', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.embeddings.word_embeddings.char_conv_6.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.embeddings.word_embeddings._highways._layers.1.weight', 'bert.embeddings.word_embeddings.char_conv_0.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.embeddings.word_embeddings._highways._layers.0.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.embeddings.word_embeddings.char_conv_1.bias', 'bert.embeddings.word_embeddings.char_conv_2.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.embeddings.word_embeddings.char_conv_4.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.embeddings.word_embeddings._highways._layers.1.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.embeddings.word_embeddings.char_conv_1.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.embeddings.word_embeddings.char_conv_3.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.embeddings.word_embeddings.char_conv_6.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'classifier.bias', 'bert.embeddings.word_embeddings.char_conv_3.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.embeddings.word_embeddings.char_conv_0.bias', 'bert.embeddings.word_embeddings._char_embedding_weights', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.embeddings.word_embeddings._projection.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.embeddings.word_embeddings.char_conv_4.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'classifier.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.embeddings.word_embeddings.char_conv_2.bias', 'bert.embeddings.word_embeddings._projection.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.embeddings.word_embeddings.char_conv_5.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.embeddings.word_embeddings.char_conv_5.bias']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CharacterBertModel were not initialized from the model checkpoint at models/bert-unigram-bengali-classifier and are newly initialized: ['encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'embeddings.word_embeddings.char_conv_6.bias', 'encoder.layer.9.output.LayerNorm.bias', 'embeddings.word_embeddings.char_conv_1.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'embeddings.word_embeddings._char_embedding_weights', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'embeddings.word_embeddings.char_conv_5.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'embeddings.word_embeddings._highways._layers.1.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.char_conv_3.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'embeddings.word_embeddings.char_conv_2.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'embeddings.word_embeddings.char_conv_3.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'embeddings.word_embeddings._highways._layers.0.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.char_conv_4.bias', 'embeddings.word_embeddings._projection.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.char_conv_5.bias', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.word_embeddings.char_conv_6.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'embeddings.word_embeddings._projection.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.char_conv_2.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'embeddings.word_embeddings.char_conv_1.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'embeddings.word_embeddings.char_conv_0.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'embeddings.word_embeddings.char_conv_4.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'embeddings.word_embeddings._highways._layers.0.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'embeddings.word_embeddings.char_conv_0.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'embeddings.word_embeddings._highways._layers.1.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\"models/bert-unigram-bengali-classifier\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2bb49f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterCnn(\n",
       "  (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "  (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "  (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "  (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "  (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "  (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "  (_highways): Highway(\n",
       "    (_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d323c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): CharacterBertModel(\n",
       "    (embeddings): CharacterBertEmbeddings(\n",
       "      (word_embeddings): CharacterCnn(\n",
       "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "        (_highways): Highway(\n",
       "          (_layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      )\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CharacterBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CharacterBertLayer(\n",
       "          (attention): CharacterBertAttention(\n",
       "            (self): CharacterBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CharacterBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CharacterBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): CharacterBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): CharacterBertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"models/bert-unigram-bengali-classifier\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7045df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705888d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset indic_glue (C:/Users/arifa/.cache/huggingface/datasets/indic_glue/bbca.hi/1.0.0/082910ba488a202e0b57bfff0222f736130a17028e9ff242e4d537bd2fe6cd95)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "news_datasets = load_dataset(\"indic_glue\",\"bbca.hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f74f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 3467\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 866\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c44db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_datasets[\"train\"].set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7386598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = news_datasets[\"train\"][\"label\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fd91ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "india              1389\n",
       "international       904\n",
       "entertainment       285\n",
       "sport               258\n",
       "news                230\n",
       "science             194\n",
       "business             54\n",
       "pakistan             43\n",
       "southasia            42\n",
       "institutional        19\n",
       "social               18\n",
       "china                14\n",
       "multimedia           12\n",
       "learningenglish       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9848d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_datasets[\"train\"].reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698c93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "# set_seed(30)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae60928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CharacterBertTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = CharacterBertTokenizer(strip_accents=None, do_lower_case=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6eac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig, CharacterBertModel, CharacterBertTokenizer\n",
    "\n",
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)  # binary classification\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85c0ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    \"E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b833509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    #return tokenizer(example[\"text\"], truncation=True)\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38859875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\indic_glue\\bbca.hi\\1.0.0\\082910ba488a202e0b57bfff0222f736130a17028e9ff242e4d537bd2fe6cd95\\cache-d88d59429e7ba57b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\indic_glue\\bbca.hi\\1.0.0\\082910ba488a202e0b57bfff0222f736130a17028e9ff242e4d537bd2fe6cd95\\cache-8c0e741a951db135.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_datasets = news_datasets.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c5c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3467\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 866\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e711f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"india\": 0,\n",
    "# \"international\": 1,\n",
    "# \"entertainment\": 2,\n",
    "# \"sport\":3,\n",
    "# \"news\": 4,\n",
    "# \"science\": 5,\n",
    "# \"business\": 6,\n",
    "# \"pakistan\": 7,\n",
    "# \"southasia\":8,\n",
    "# \"institutional\":  9,\n",
    "# \"social\":10,\n",
    "# \"china\": 11,\n",
    "# \"multimedia\":  12,\n",
    "# \"learningenglish\": 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b77cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\n",
    "        \"india\": 0,\n",
    "        \"international\": 1,\n",
    "        \"entertainment\": 2,\n",
    "        \"sport\":3,\n",
    "        \"news\": 4,\n",
    "        \"science\": 5,\n",
    "        \"business\": 6,\n",
    "        \"pakistan\": 7,\n",
    "        \"southasia\":8,\n",
    "        \"institutional\":  9,\n",
    "        \"social\":10,\n",
    "        \"china\": 11,\n",
    "        \"multimedia\":  12,\n",
    "        \"learningenglish\": 13\n",
    "    }\n",
    "    example['label'] = mapping[example['label']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f72f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\indic_glue\\bbca.hi\\1.0.0\\082910ba488a202e0b57bfff0222f736130a17028e9ff242e4d537bd2fe6cd95\\cache-c4601a3e57037428.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\indic_glue\\bbca.hi\\1.0.0\\082910ba488a202e0b57bfff0222f736130a17028e9ff242e4d537bd2fe6cd95\\cache-9344ad9a11970411.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'test': ['label', 'input_ids', 'token_type_ids', 'attention_mask']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(assign_label)\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399bf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] मेट्रो की इस लाइन के चलने से दक्षिणी दिल्ली से नोएडा जाने का समय काफी कम हो जाएगा और यात्रियों को राजीव चौक या मंडी हाउस से होकर नहीं जाना पड़ेगा. लेकिन, यह मजेंटा लाइन इसलिए भी महत्वपूर्ण है क्योंकि इस पर ड्राइवलैस यानी बिना ड्राइवर वाली मेट्रो चलाने की योजना है. ऐसा भारत में पहली बार होगा जब कोई मेट्रो बिना ड्राइवर के चलाई जाएगी. मेट्रो के तीसरे फेज में भारत में पहली बार ड्राइवरलेस तकनीक आएगी लेकिन दुनिया भर में कई देशों में ड्राइवरलेस मेट्रो पहले से ही चलती हैं. इन देशों में ड्राइवरलेस मेट्रो सफल भी रही हैं. दक्षिण कोरिया की राजधानी सोल में ड्राइवलेस ट्रेन कामयाबी से चल रही है. ये मेट्रो ज़मीन के नीचे [SEP]'\n",
      "\n",
      "'>>> [CLS] नेटिजन यानि इंटरनेट पर सक्रिय नागरिक अब ट्विटर पर सरकार द्वारा लगाए प्रतिबंधों के समर्थन या विरोध में अपने विचार व्यक्त करते हैं और वेबसाइट संबंधी सूचना भी जारी करते हैं. कुछ दिन पहले ही शियाओं के खिलाफ़ हिंसा पर नज़र रखनेवाली एक प्रतिबंधित वेबसाइट शियाकिलिंग. कॉम को ट्विटर पर चलाए अभियान और सड़कों पर हुए प्रदर्शन के बाद बहाल कर दिया गया था. उससे कुछ दिन पहले जब अहमदिया संप्रदाय की आधिकारिक वेबसाइट अलइस्लाम. ओआरजी को ब्लॉक कर दिया गया था तो ट्विटर पर अहमदिया शब्द काफी प्रचलित हो गया था. पाकिस्तान के संविधान में अहमदिया संप्रदाय के लोगों को मुसलमान नहीं माना जाता है. अतीत में भी शिया, अहमदिया, बलोच और सिंधी जैसे सांप्रदायिक समूहों की [SEP]'\n",
      "\n",
      "'>>> [CLS] इसमें एक फ़्लाइट एटेनडेंट की मदद की गुहार है और साथ में डिक चेनी के उस निर्देश का ज़िक्र है जिसमें उन्होंने विमानों को मार गिराने की बात की थी. एक अपहरणकर्ता मोहम्मद अता की धमकियाँ भी सुनी जा सकती हैं. ये ऑडियो 9 / 11 आयोग के लिए तैयार किया गया था. ज़्यादातर बातें लिखित रूप में प्रकाशित की जा चुकी हैं. रिकॉर्डिंग में अमेरिकन एयरलाइन्स के फ़्लाइट नंबर 11 की फ़्लाइट एटेनडेंट बेटी का फ़ोन कॉल भी है. वे बोल रही हैं, \" बिज़नस श्रेणी में किसी को स्टैब किया गया है. पता नहीं, लगता है कि हमारा अपहरण किया जा रहा है. \" अपहरणकर्ता मोहम्मद अता को बोलते हुए सना जा सकता है, [SEP]'\n",
      "\n",
      "'>>> [CLS] प्रतीक खुलेपन का, आज़ाद ख्याली का और भीड़ से अलग हो जाने का. सवा सौ साल के इतिहास वाले इस मोटरसाइकिल ब्रांड ने दोनों विश्व युद्ध का घमासान भी देखा है और सैकड़ों उतार चढ़ाव भी. साल 1970 में रॉयल एन्फील्ड ने ब्रिटेन समेत दुनियाभर में अपना उत्पादन रोक दिया, लेकिन भारत में इसका उत्पादन जारी रहा. भारत में पुलिस फोर्स से लेकर सेना तक ने अपनी कठिन जीवनशैली में शामिल करने के लिए लोहे से बनी बुलेट को कारगर पाया. पीढ़ियों से रॉयल एन्फील्ड मोटरसाइकिलों के शौकीन अनुज वशिष्ठ कहते हैं, “ मै जब छोटा था तो पिताजी की बुलेट को बर्डी कहता था, आज मेरा बेटा जब बड़ा हो रहा है तो वो उस बुलेट को [SEP]'\n",
      "\n",
      "'>>> [CLS] ख़ासकर पिछले 10 साल तक प्रधानमंत्री रहे मनमोहन सिंह को सुनने के बाद तो यह भाषण शानदार लगता है. लेकिन पिछले कई प्रधानमंत्रियों के इतर मोदी के भाषण में कई तरह के छुपे हुए संकेत भी हैं. अंकुश रखने की इच्छा, एकाधिकार की चाह के संकेत जो मोदी की कार्यशैली में अभी से दिखने लगे हैं. अपनी इस ख़ासियत से मोदी पूर्व प्रधानमंत्री इंदिरा गांधी के नज़दीक पहुंच जाते हैं. प्रधानमंत्री नरेंद्र मोदी ने ऐतिहासिक लालकिले से अपने पहले भाषण में वही साबित किया जो करने की उन्हें कोई ज़रूरत नहीं थी. देश ने चुनाव प्रचार के दौरान बार - बार देखा सुना था कि वह कितने अच्छे वक्ता हैं और बार - बार अनुप्रास अलंकार का इस्तेमाल करते हैं [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(5)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75eca670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['india', 'pakistan', 'news', 'india', 'india'],\n",
       " 'text': ['मेट्रो की इस लाइन के चलने से दक्षिणी दिल्ली से नोएडा जाने का समय काफी कम हो जाएगा और यात्रियों को राजीव चौक या मंडी हाउस से होकर नहीं जाना पड़ेगा.लेकिन, यह मजेंटा लाइन इसलिए भी महत्वपूर्ण है क्योंकि इस पर ड्राइवलैस यानी बिना ड्राइवर वाली मेट्रो चलाने की योजना है. ऐसा भारत में पहली बार होगा जब कोई मेट्रो बिना ड्राइवर के चलाई जाएगी. मेट्रो के तीसरे फेज में भारत में पहली बार ड्राइवरलेस तकनीक आएगी लेकिन दुनिया भर में कई देशों में ड्राइवरलेस मेट्रो पहले से ही चलती हैं. इन देशों में ड्राइवरलेस मेट्रो सफल भी रही हैं. दक्षिण कोरिया की राजधानी सोल में ड्राइवलेस ट्रेन कामयाबी से चल रही है. ये मेट्रो ज़मीन के नीचे चलती है इसमें ड्राइवर का केबिन भी नहीं होता है. यूरोप में डेनमार्क, स्पेन, इटली, फ्रांस, जर्मनी, हंगरी, स्विट्जरलैंड और ब्रिटेन में भी ड्राइवरलैस मेट्रो चलती है. इन देशों में एक से ज़्यादा शहरों में भी ऐसी मेट्रो चलाई जाती है. इनके अलावा अमेरिका और कनाडा में भी ड्राइवरलेस ट्रेन चलती है. वहीं, ब्राजील, पेरू और चाइल में भी इस तरह की मेट्रो काफ़ी पहले आ चुकी है. भारत के पड़ोसी देश चीन में भी ड्राइवरलेस मेट्रो चलती है. अगर आप सऊदी अरब, क़तर और सिंगापुर जाएं तो वहां भी आप बिना ड्राइवर की मेट्रो का मज़ा उठा सकते हैं. क्या है मेट्रो में ख़ास?ड्राइवरलेस मेट्रो जैसा कि नाम से ही पता चला है कि इसे चलाने के लिए ड्राइवर की ज़रूरत नहीं पड़ती है. साथ ही यह मेट्रो किसी रुकावट को पहचानने और आपातकालीन परिस्थितियों में स्वचालित तरीके से काम करती है. इसमें भले ही ड्राइवर न हो लेकिन इसकी हर गतिविधि पर नज़र रखी जाती है. कौन सी ट्रेन कहां है, किस गति से चल रही है और किसे कहां रुकना है ये सब कुछ स्वचालित होता है. भारत की ड्राइवरलेस मेट्रो के बारे में कहा जा रहा है कि इसमें ज़्यादा यात्री सफ़र कर सकेंगे और इसमें ऊर्जा की भी कम खपत होगी. जिन स्टेशनों से होकर ये ट्रेन गुजरेगी उन प्लेटफॉर्म पर स्क्रीन डोर लगे होंगे. ये स्क्रीन डोर सुरक्षा के लिए लगाए गए हैं ताकि प्लेटफॉर्म पर मौजूद यात्री ट्रैक पर न जा सकें. ये दरवाजे तभी खुलेंगे जब मेट्रो प्लेटफॉर्म पर आकर रुकेगी. साथ ही इस बार मेट्रों में कुर्सियों का रंग भी बदलकर संतरी और लाल रखा गया है. हाल ही में कालिंदी कुंज डिपो में एक ड्राइवरलैस मेट्रो के साथ दुर्घटना भी हो गई थी. मेट्रो यार्ड की दीवार तोड़कर बाहर निकल गई थी. पहले इसे ट्रायल रन के दौरान हुआ हादसा बताया गया लेकिन दिल्ली मेट्रो ने इसे मेंटनेंस के बाद हुई दुर्घटना कहा था. इसमें इंसानी ग़लती होने की आशंका जताई थी. हालांकि, इस हादसे में किसी को चोट नहीं पहुंची थी. (बीबीसी हिन्दी के एंड्रॉएड ऐप के लिए आप यहां क्लिक कर सकते हैं. आप हमें फ़ेसबुक और ट्विटर पर फ़ॉलो भी कर सकते हैं.)',\n",
       "  'नेटिजन यानि इंटरनेट पर सक्रिय नागरिक अब ट्विटर पर सरकार द्वारा लगाए प्रतिबंधों के समर्थन या विरोध में अपने विचार व्यक्त करते हैं और वेबसाइट संबंधी सूचना भी जारी करते हैं.कुछ दिन पहले ही शियाओं के खिलाफ़ हिंसा पर नज़र रखनेवाली एक प्रतिबंधित वेबसाइट शियाकिलिंग.कॉम को ट्विटर पर चलाए अभियान और सड़कों पर हुए प्रदर्शन के बाद बहाल कर दिया गया था.उससे कुछ दिन पहले जब अहमदिया संप्रदाय की आधिकारिक वेबसाइट अलइस्लाम.ओआरजी को ब्लॉक कर दिया गया था तो ट्विटर पर अहमदिया शब्द काफी प्रचलित हो गया था.पाकिस्तान के संविधान में अहमदिया संप्रदाय के लोगों को मुसलमान नहीं माना जाता है.अतीत में भी शिया, अहमदिया, बलोच और सिंधी जैसे सांप्रदायिक समूहों की वेबसाइटें प्राय: प्रतिबंधित की जाती रही हैं.पाकिस्तान के दूरसंचार प्राधिकरण के प्रमुख का कहना है कि हाल ही में क़रीब 15,756 वेबसाइटों को ब्लॉक कर दिया गया है जिनमें ईशनिंदा और अश्लील सामग्री वाली वेबसाइटें शामिल हैं.पाकिस्तान में ट्विटर, फेसबुक और यू-ट्यूब को भी कुछ समय के लिए ब्लॉक किया गया था.इस साल की शुरुआत में पाकिस्तान सरकार को वेबसाइटों पर नज़र रखने के लिए एक तंत्र विकसित करने के प्रस्ताव को लेकर आलोचना का सामना भी करना पड़ा था.',\n",
       "  'इसमें एक फ़्लाइट एटेनडेंट की मदद की गुहार है और साथ में डिक चेनी के उस निर्देश का ज़िक्र है जिसमें उन्होंने विमानों को मार गिराने की बात की थी.एक अपहरणकर्ता मोहम्मद अता की धमकियाँ भी सुनी जा सकती हैं. ये ऑडियो 9/11 आयोग के लिए तैयार किया गया था. ज़्यादातर बातें लिखित रूप में प्रकाशित की जा चुकी हैं.रिकॉर्डिंग में अमेरिकन एयरलाइन्स के फ़्लाइट नंबर 11 की फ़्लाइट एटेनडेंट बेटी का फ़ोन कॉल भी है.वे बोल रही हैं,\"बिज़नस श्रेणी में किसी को स्टैब किया गया है. पता नहीं, लगता है कि हमारा अपहरण किया जा रहा है.\"अपहरणकर्ता मोहम्मद अता को बोलते हुए सना जा सकता है, \"कोई हिलेगा नहीं, ऐसे में सब ठीक रहेगा. अगर किसी ने कुछ करने की कोशिश की तो आपको नुकसान हो सकता है और विमान को भी. चुपचाप बैठे रहें.\"ज़्यादातर रिकॉर्डिंग फ़ेडरल एविएशन एडमिनिस्ट्रेशन की है. जब विमान वर्ल्ड ट्रेड सेंटर से टकरा चुका था तो उसके बाद ऑडियो में सुना जा सकता है कि कन्ट्रोलर एक और विमान की बात कर रहे हैं जो मैनहेटन जा रहा है.ऑडियो में एक आवाज़ है जो बोल रही है,\"एक और विमान अभी-अभी वर्ल्ड ट्रेड सेंटर से टकराया है.\" फिर कोई कहता है,\" पूरी इमारत बिखर गई है.\"अफ़रा-तफ़री के आलम में जब कुछ फ़ाइटर जेट पूर्व की ओर उड़ान भरते हैं तो एक सैन्य कमांडर उन्हें जल्द से जल्द वाशिंगटन आने का आदेश देते हुए सुने जा सकते हैं.आख़िरी विमान यूनाइटेड 93 के पेनसल्वेनिया में गिरने से पहले मेजर केविन ये कहते हुए सुने जा सकते हैं, \"मुझे इस बात की परवाह नहीं कि आप कितनी खिड़कियाँ तोड़ देते हैं.\"',\n",
       "  'प्रतीक खुलेपन का, आज़ाद ख्याली का और भीड़ से अलग हो जाने का.सवा सौ साल के इतिहास वाले इस मोटरसाइकिल ब्रांड ने दोनों विश्व युद्ध का \\n\\n\\n\\n\\n\\nघमासान भी देखा है और सैकड़ों उतार चढ़ाव भी.साल 1970 में रॉयल एन्फील्ड ने ब्रिटेन समेत दुनियाभर में अपना उत्पादन रोक दिया, लेकिन भारत में इसका उत्पादन जारी रहा.भारत में पुलिस फोर्स से लेकर सेना तक ने अपनी कठिन जीवनशैली में शामिल करने के लिए लोहे से बनी बुलेट को कारगर पाया.पीढ़ियों से रॉयल एन्फील्ड मोटरसाइकिलों के शौकीन अनुज वशिष्ठ कहते हैं, “मै जब छोटा था तो पिताजी की बुलेट को बर्डी कहता था, आज मेरा बेटा जब बड़ा हो रहा है तो वो उस बुलेट को ग्रैनी कहता है. बुलेट कई वर्षों से हमारे परिवार का हिस्सा है.”लेकिन कुछ दशक पहले तक बाइक प्रेमियों के बीच बुलेट का जितना नाम था उतना ही ये बदनाम भी था. पुरानी तकनीक से बनी इस बेहद वजनी गाड़ी की आलोचना भी खूब हुई.लेकिन बुलेट के दीवाने बुलेट के दीवाने ही रहे.वक्त के साथ कंपनी ने बुलेट में कई तकनीकी बदलाव भी किए, लेकिन आवाज़ और ताकत से छेड़छाड़ कम ही हुई.भारत सहित दुनिया के अन्य देशों में आज भी भारत में बनी बुलेट निर्यात की जाती है.प्रोफ़ेशनल बाइकर सपन अपनी बुलेट ‘क्लासिक’ मोटरसाइकिल को अपना एक हिस्सा मानते है.वो कहते है, “ये मेरे लिए सिर्फ एक बाइक न होकर मेरी लाइफ़स्टाइल भी है. इस पर सवार होकर लगता है कि मुझ में ही पहिए लग गए हो. मेरे हिस्से जैसा है ये.”इस हैन्डक्राफ़्टेड बाइक की खुद भारत में इतनी मांग है कि ग्राहकों को इसके लिए कई दिनों का इंतज़ार करना पड़ता है.भारतीय और अंतरराष्ट्रीय बाज़ारों में कई सस्ते और उन्नत तकनीक के विकल्प मौजूद होने के बाद भी रॉयल एन्फील्ड मोहल्ले के दूधवाले से लेकर प्रोफ़ेशनस बाइक राइडर्स की पसंद बनी हुई है.भारतीय सड़कों पर बुलेट वर्षों से शान और रुतबे का परिचायक बनकर दौड़ता रहा.लेकिन खास बात ये है कि जिस कंपनी का नामोनिशान खुद उसके देश से सालों पहले उजड़ गया वो भारत में आज भी कायम है.',\n",
       "  \"ख़ासकर पिछले 10 साल तक प्रधानमंत्री रहे मनमोहन सिंह को सुनने के बाद तो यह भाषण शानदार लगता है.लेकिन पिछले कई प्रधानमंत्रियों के इतर मोदी के भाषण में कई तरह के छुपे हुए संकेत भी हैं.अंकुश रखने की इच्छा, एकाधिकार की चाह के संकेत जो मोदी की कार्यशैली में अभी से दिखने लगे हैं.अपनी इस ख़ासियत से मोदी पूर्व प्रधानमंत्री इंदिरा गांधी के नज़दीक पहुंच जाते हैं.प्रधानमंत्री नरेंद्र मोदी ने ऐतिहासिक लालकिले से अपने पहले भाषण में वही साबित किया जो करने की उन्हें कोई ज़रूरत नहीं थी.देश ने चुनाव प्रचार के दौरान बार-बार देखा सुना था कि वह कितने अच्छे वक्ता हैं और बार-बार अनुप्रास अलंकार का इस्तेमाल करते हैं.एक ही बात दस तरह से कहते हैं और कहते रहते हैं जब तक वह दिल-दिमाग में बैठ न जाए.मोदी के व्यक्तित्व के इस पहलू पर शायद ही कोई सवाल उठाए, इसके बावजूद उन्होंने भाषण कला फिर प्रदर्शित की. जमकर मुहावरेदारी की, नारे दिए और जुमले उछाले.लोग उन्हें अरसे तक दोहराते रहेंगे. ऐसा एक लंबे वक्त के बाद हुआ है.एक दशक तक संयुक्त प्रगतिशील गठबंधन के मनमोहन सिंह के बेजान, थकाऊ और उबाऊ भाषणों के बरअक्स मोदी ताज़ा हवा का झोंका थे- सुखद और कानों को अच्छा लगने वाला.यह अब तक देश के सबसे अच्छे और प्रखर वक्ता अटल बिहारी वाजपेयी के भाषणों से भिन्न था.वाजपेयी के भाषण में लय, ज्ञेयता और कविताई थी, जो मोदी के भाषण में ग़ायब थी.वाजपेयी दिल को छू लेते थे तो मोदी दिल के साथ जेब भी छूते हैं. व्यापार का महत्व वह अच्छी तरह समझते हैं ख़ासकर नए वैश्विक परिवेश में.यह वाजपेयी से एक कदम आगे है या पीछे, बाद में तय होगा.सुना है पहले प्रधानमंत्री जवाहरलाल नेहरू दिल से बोलते थे, लाल बहादुर शास्त्री भी. इंदिरा गांधी दिल से ज़्य़ादा दिमाग़ का इस्तेमाल करती थीं.राजीव गांधी सपाट वक्ता थे जबकि नरसिम्हा राव में विद्वता थी. मोरारजी देसाई में अपने किस्म की अकड़ नज़र आती थी.वीपी सिंह कभी अकड़े, कभी डरे हुए लगते थे कि पता नहीं कब तक चलेंगे. मनमोहन सिंह तो लगता था कि ख़ुद से बात कर रहे हैं. लुटपुटाती ज़ुबान में ख़ुद बोला ख़ुद सुन लिया.उनकी बोली और ख़ामोशी में ज़्यादा फ़र्क नहीं था. मोदी की शक्ल में पहली बार संवाद करने वाला प्रधानमंत्री देश को मिला है, आंखों में आंखें डालकर बोलता.इस ज़िद के साथ कि वह समझाता ही रहेगा, दोहरा-तिहरा कर बोलेगा कि कैसे और कब तक नहीं समझोगे.मोदी के भाषण में जो विषय उठाए गए, छूटे या छोड़ दिए गए उन्हें हटा दें तो सिर्फ़ अदा और अदायगी के लिए उन्हें 10 में से 10 नंबर दिए जा सकते हैं.अगर कटा तो आधा नंबर सिर्फ़ इसलिए कटेगा कि वह आधा वाक्य संस्कृत में बोले और उसमें भी उच्चारण दोष था.अगर प्रधानमंत्री के भाषण के संकेतों को देखा जाए तो एक संकेत बहुत साफ़ था और उसकी झलक दो बार अलग-अलग संदर्भों में देखने को मिली.पहली जब मोदी ने 'लड़कियों से कहां जाओगी, कब आओगी' जैसे सवालों का ज़िक्र किया और कहा कि यही सवाल लड़कों से क्यों नहीं पूछे जाते.उन पर मां-बाप अंकुश रखें तो बलात्कार और आतंकवादी हिंसा जैसी घटनाएं न हों. वह सब पर अंकुश चाहते हैं.दूसरी झलक में वह ख़ुद को दिल्ली में बाहरी बताते हैं. कहते हैं कि अंदर से देखा तो पाया कि यहां एक सरकार के अंदर कई सरकारें चलती हैं.अदालतों में मुक़दमे होते हैं जो देश के लिए क़तई ठीक नहीं हैं. इससे मोदी की एकाधिकारवादी मनोवृत्ति दिखाई देती है.यह छवि अख़बारों और सोशल मीडिया में प्रसारित उस छवि का विस्तार लगती है जिसमें अपने सांसदों से बात करते हुए मोदी डेढ़ फुट ऊंचे मंच पर बैठते हैं.बाक़ी सब नीचे रखी कुर्सियों पर. लोकतंत्र का मान्य सिद्धांत प्रधानमंत्री को कोई ऊंचा आसन नहीं देता बल्कि उन्हें 'फर्स्ट अमंग इक्वल' मानता है.इस सिद्धांत के टूटने की पहली घटना इंदिरा गांधी के काल में हुई थी, जिन्हें 'ओनली मैन इन हर कैबिनेट', कहा जाने लगा था. लेकिन इस बार जो हो रहा है, उसे क्या कहेंगे?(बीबीसी हिन्दी के एंड्रॉएड ऐप के लिए \\n\\n\\n\\nयहां क्लिक करें. आप हमें \\n\\n\\n\\nफ़ेसबुक और \\n\\n\\n\\nट्विटर पर भी फ़ॉलो कर सकते हैं.)\"]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae60094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f49e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([32, 128, 50]),\n",
       " 'token_type_ids': torch.Size([32, 128]),\n",
       " 'attention_mask': torch.Size([32, 128]),\n",
       " 'labels': torch.Size([32])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f39d52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6730) torch.Size([32, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09c186ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_fun = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_result = metric_fun.compute(references=labels, predictions=predictions)\n",
    "    return {\n",
    "        \"accuracy\": metric_result[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cb53020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "324b2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    report_to = None,\n",
    "    output_dir=\"models/bbc-classifier\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    #learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.02,\n",
    "    #warmup_ratio=0.05,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=6,\n",
    "    #num_train_epochs=4,\n",
    "    #push_to_hub=True,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d94821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# entire_train = concatenate_datasets([tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8085d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #train_dataset=entire_train,\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7440206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3467\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 04:56, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.252800</td>\n",
       "      <td>0.993218</td>\n",
       "      <td>0.700924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>0.878949</td>\n",
       "      <td>0.751732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.753700</td>\n",
       "      <td>0.845290</td>\n",
       "      <td>0.758661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.760970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.822459</td>\n",
       "      <td>0.759815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.452700</td>\n",
       "      <td>0.837284</td>\n",
       "      <td>0.760970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=654, training_loss=0.7522476714685422, metrics={'train_runtime': 299.44, 'train_samples_per_second': 69.47, 'train_steps_per_second': 2.184, 'total_flos': 8.32504219679232e+16, 'train_loss': 0.7522476714685422, 'epoch': 6.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f026e2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 866\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8372840881347656,\n",
       " 'eval_accuracy': 0.7609699769053118,\n",
       " 'eval_runtime': 5.3251,\n",
       " 'eval_samples_per_second': 162.626,\n",
       " 'eval_steps_per_second': 5.258,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "036d1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d323c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"models/bert-unigram-bengali-classifier\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddefcfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.47230616211891174,\n",
       " 'eval_accuracy': 0.9029057406094968,\n",
       " 'eval_runtime': 3.4463,\n",
       " 'eval_samples_per_second': 409.426,\n",
       " 'eval_steps_per_second': 13.058,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

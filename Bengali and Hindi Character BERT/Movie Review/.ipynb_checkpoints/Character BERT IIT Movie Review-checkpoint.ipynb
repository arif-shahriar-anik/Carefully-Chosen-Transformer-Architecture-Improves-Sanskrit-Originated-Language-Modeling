{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705888d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/arifa/.cache/huggingface/datasets/csv/default-ed77443b5b6f9146/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68ae2f9c3f440fc9fcd70aa2f392bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e57ccc096a45e48e527b103924e52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/arifa/.cache/huggingface/datasets/csv/default-ed77443b5b6f9146/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "column_names=[\"labels\",\"text\"]\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-movie-reviews\\hi\\hi-train.csv\", split=\"train\", column_names=column_names, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf443ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/arifa/.cache/huggingface/datasets/csv/default-2d3fe06acaa4bb9d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac4474ff3e14e90ba90911534aaf26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3307fb379f47309f06b984559d6f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/arifa/.cache/huggingface/datasets/csv/default-2d3fe06acaa4bb9d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "val_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-movie-reviews\\hi\\hi-valid.csv\", split=\"train\", column_names=[\"labels\",\"text\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b105db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/arifa/.cache/huggingface/datasets/csv/default-f6e28a31ac478956/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2529663114214a7b878660e64f548707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f5feb12cb949f1b99e3b9ea8061884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/arifa/.cache/huggingface/datasets/csv/default-f6e28a31ac478956/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files=\"..\\datasets\\iitp-movie-reviews\\hi\\hi-test.csv\", split=\"train\", column_names=[\"labels\",\"text\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971c96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "review_datasets = DatasetDict()\n",
    "review_datasets['train'] = train_dataset\n",
    "review_datasets['validation'] = val_dataset\n",
    "review_datasets['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6758cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 2480\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c44db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7386598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label counts for both classes\n",
    "label_counts = train_dataset[\"labels\"].value_counts()\n",
    "num_labels = (len(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fd91ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "positive    1042\n",
       "negative     741\n",
       "neutral      697\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcd1891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length = max(train_dataset['text'].str.len())\n",
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9848d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "698c93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "# set_seed(30)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef4cce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\arifa/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig, CharacterBertModel, CharacterBertTokenizer\n",
    "\n",
    "#### LOADING BERT FOR CLASSIFICATION ####\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)  # binary classification\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9ebb300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpiece embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d824c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\\config.json\n",
      "Model config CharacterBertConfig {\n",
      "  \"_name_or_path\": \"helboukkouri/character-bert\",\n",
      "  \"architectures\": [\n",
      "    \"CharacterBertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_character_bert.CharacterBertConfig\",\n",
      "    \"AutoModel\": \"modeling_character_bert.CharacterBertForPreTraining\",\n",
      "    \"AutoModelForMaskedLM\": \"modeling_character_bert.CharacterBertForMaskedLM\"\n",
      "  },\n",
      "  \"character_embeddings_dim\": 16,\n",
      "  \"cnn_activation\": \"relu\",\n",
      "  \"cnn_filters\": [\n",
      "    [\n",
      "      1,\n",
      "      32\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      32\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      64\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      128\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      256\n",
      "    ],\n",
      "    [\n",
      "      6,\n",
      "      512\n",
      "    ],\n",
      "    [\n",
      "      7,\n",
      "      1024\n",
      "    ]\n",
      "  ],\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_word_length\": 50,\n",
      "  \"mlm_vocab_size\": 30522,\n",
      "  \"model_type\": \"character_bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_highway_layers\": 2,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "loading weights file E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi were not used when initializing CharacterBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing CharacterBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CharacterBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of CharacterBertModel were initialized from the model checkpoint at E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CharacterBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#### REPLACING BERT WITH CHARACTER_BERT ####\n",
    "\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    \"E:\\Documents\\Character Bert\\Hate Speech\\character-bert-hindi\")\n",
    "model.bert = character_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30f7c44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterCnn(\n",
       "  (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "  (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "  (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "  (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "  (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "  (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "  (_highways): Highway(\n",
       "    (_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings  # wordpieces are replaced with a CharacterCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ae60928",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterBertTokenizer(strip_accents=None, do_lower_case=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "894a223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_added_tokens = tokenizer.add_tokens([\"5\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7de20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b833509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    #return tokenizer(example[\"text\"], truncation=True)\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "38859875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-ed77443b5b6f9146\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-6a0d0c225c17682f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-2d3fe06acaa4bb9d\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-39d97ff987fcc5e8.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-f6e28a31ac478956\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-f5c14009cf97aedd.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenized_datasets = review_datasets.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "90c5c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2480\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5648aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-ed77443b5b6f9146\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-d79efed9b02984a6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-2d3fe06acaa4bb9d\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-d8f98101423690c5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-f6e28a31ac478956\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0587b380a6f31363.arrow\n"
     ]
    }
   ],
   "source": [
    "temp = tokenized_datasets.filter(lambda x:x if 0 in x[\"input_ids\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fedfc6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b77cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(example):\n",
    "    mapping = {\"neutral\":0, \"positive\":1, \"negative\":2}\n",
    "    example['labels'] = mapping[example['labels']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f72f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-ed77443b5b6f9146\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b46e177ef201b685.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-2d3fe06acaa4bb9d\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-22be047da9787ee0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\arifa\\.cache\\huggingface\\datasets\\csv\\default-f6e28a31ac478956\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-7d02467385cceac5.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'validation': ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'test': ['labels', 'input_ids', 'token_type_ids', 'attention_mask']}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(assign_label)\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "399bf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] निर्माता : शीतल विनोद तलवार, मधु मैंटेना निर्देशक : रामगोपाल वर्मा कलाकार : विवेक ओबेरॉय, शत्रुघ्न सिन्हा, अभिमन्यु सिंह, सुशांत सिंह, जरीन वहाब, आशीष विद्यार्थी, राजा कृष्णमूर्ति, श्रीनिवास राव * केवल वयस्कों के लिए * 16 रील * 2 घंटे 14 मिनट ’ रक्तचरित्र - 1 ’ शुरू होते ही स्पष्टीकरण लिखा हुआ आता है कि सारे पात्र और कहानी काल्पिनक हैं । अगले ही पल दिखाई देता है कि फिल्म एक सच्ची कहानी पर आधारित है । शायद कानूनी उलझनों से बचने के लिए रामगोपाल वर्मा को विरोधाभास बातें साथ करनी पड़ी हो । ‘ रक्तचरित्र ’ की कहानी आंध्रप्रदेश के रवि परिताला और उसके विरोधी सूरी पर आधारित है । रामू ने उससे प्रेरणा लेकर, [SEP]'\n",
      "\n",
      "'>>> [CLS] ’ उड़ान ’ से विक्रमादित्य मोटवाने ने अच्छे सिनेमा की उम्मीद जगाई थी और ‘ लुटेरा ’ में उन्होंने उम्मीदों को पूरा किया । एक बेहतरीन प्रेम कहानी लंबे समय बाद परदे पर आई है । ओ हेनरी की कहानी ‘ द लास्ट लीफ ’ को आधार बनाकर उसे गुजरे जमाने का टच दिया और अपने शानदार प्रस्तुति के बल पर विक्रम ने ’ लुटेरे ’ को देखने लायक बनाया है । पूरी फिल्म में निर्देशक का दबदबा है । उन्होंने दूसरी चीजों को हावी नहीं होने दिया और अपनी पकड़ बनाए रखी है । कई बार कहानी हिचकोले खाती है, लेकिन विक्रमादित्य ने इन झटकों को भी अच्छी तरह संभाल लिया है । कहानी पचास के दशक में सेट है । माणिकपुर का जमींदार [SEP]'\n",
      "\n",
      "'>>> [CLS] फिल्म में गानों के दृश्य में अनुष्का को माइक के सामने लक - दक कॉस्ट़्यूम में खड़े होकर गीतों के भाव को चेहरे पर लाना था । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] फांसी चढ़ने से पहले वह पाकिस्तान के सदर से खास इजाजत लेकर मीडिया से मुखातिब होती है [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] राज कुमार हिरानी ने इस मूवी में भी अपने डायरेक्शन का जलवा दिखा दिया । उन्होंने साबित कर दिया कि उनके पिटारे से हर बार कुछ अलग और नया निकलता है । कहानी पर हिरानी की शुरू से आखिर तक पकड़ है । आमिर के रहते शरमन, माधवन, बोमन से हिरानी ने बेहतरीन काम लिया और हर एक की मौजूदगी को फिल्म का अहम हिस्सा बनाया । एक पल भी कहानी की गति को उन्होंने सुस्त नहीं पड़ने दिया । [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(5)]\n",
    "samples\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75eca670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['neutral', 'positive', 'neutral', 'neutral', 'positive'],\n",
       " 'text': ['निर्माता :\\nशीतल विनोद तलवार, मधु\\u200d मैंटेना\\n\\nनिर्देशक :\\nरामगोपाल वर्मा\\n\\nकलाकार :\\nविवेक ओबेरॉय, शत्रुघ्न सिन्हा, अभिमन्यु सिंह, सुशांत सिंह, जरीन वहाब, आशीष विद्यार्थी, राजा कृष्णमूर्ति, श्रीनिवास राव\\n\\n* केवल वयस्कों के लिए * 16 रील * 2 घंटे 14 मिनट\\n\\n\\n’रक्तचरित्र-1’ शुरू होते ही स्पष्टीकरण \\u200dलिखा हुआ आता है कि सारे पात्र और कहानी काल्पिनक हैं। अगले ही \\u200dपल दिखाई देता है कि फिल्म एक सच्ची कहानी पर आधारित है। शायद कानूनी उलझनों से बचने के लिए रामगोपाल वर्मा को विरोधाभास बातें साथ करनी पड़ी हो।\\n\\n‘रक्तचरित्र’ की कहानी आंध्रप्रदेश के रवि परिताला और उसके विरोधी सूरी पर आधारित है। रामू ने उससे प्रेरणा लेकर, कुछ अपनी कल्पना मिलाकर ‘रक्तचरित्र’ को दो भागों में बनाया है।\\n\\nपहले भाग में दिखाया गया है कि किस तरह अपने पिता और भाई की हत्या होने के बाद रवि (फिल्म में प्रताप) अपना बदला लेता है। इन हत्याओं में नरसिम्हा देवा रेड्डी (राजा कृष्णमूर्ति), नागमणि रेड्डी (श्रीनिवास राव) और मंदा (आशीष विद्यार्थी) का हाथ रहता है।\\n\\nजब तीनों को प्रताप मार डालता है तो नागमणि का बेटा बुक्का रेड्डी(अभिमन्यु सिंह) उससे बदला लेने के लिए उतावला हो जाता है। बुक्का एक तरह से राक्षस है। गुस्सा उसकी नाक पर रहता है। जो लड़की पसंद आती है उसे वह उठा लेता है। क्रूरतम तरीके (गन्ने की चरखी से सिर काट देना, आरा मशीन से धड़ अलग कर देना आदि) से हत्या करना उसे पसंद है।\\n\\nबुक्का के भाई के खिलाफ एक सुपरसितारा और राजनेता (असल में एनटी रामाराव) की मदद से प्रताप चुनाव जीत जाता है और बुक्का का अंत करता है। फिल्म के दूसरे भाग में दिखाया जाएगा कि रवि की राह में सूरी नाम की एक ओर बाधा है।\\n\\nफिल्म उन लोगों के लिए रूचिकर हो सकती है, जो आंध्र प्रदेश की राजनीति को नजदीक से जानते हैं, लेकिन जो लोग इन्हें जानते नहीं हैं उन्हें यह एक रूटीन कहानी लगती है जिसमें एक-दूसरे के परिवार के सदस्यों को मारकर सिर्फ बदला लिया जा रहा है।\\n\\n‘रक्तचरित्र’ के जरिये यह बताने की कोशिश की गई है कि अभी भी भारत के कई गाँवों में जंगल राज चलता है। कुछ गुंडे किस्म के लोग ऐसे हैं, जो कानून, पुलिस, अदालत से ऊपर हैं। लेकिन इस बात को बड़े ही अतिरेक तरीके से कहा गया है। स्क्रीनप्ले कुछ इस तरह से लिखा गया है कि हिंसक दृश्यों की भरमार हो।\\n\\nफिल्म के सारे किरदार इंसानों को गाजर-मूली की तरह काट देते हैं। उनके लिए हत्याएँ करना चुटकी बजाने जैसा है, इससे फिल्म अविश्वसनीय हो गई है। दरअसल हिंसा को दिखाने के लिए अन्य बातों को ताक में रख दिया गया है।\\n\\nफिल्म में हिंसा को क्रूरतम तरीके से दिखाया गया है। हर मिनट चाकू, छुरे घोंपे जाते हैं। चारों ओर खून ही खून नजर आता है। लोगों को गोलियाँ मारी जाती हैं। हाथ-पैर-सिर काटे दिए जाते हैं। पत्थरों से सिर कुचल दिया जाता है। इतनी हिंसा देखना हर किसी के बस की बात नहीं है।\\n\\nफिल्म की शुरुआत में किरदारों का परिचय बेहद लंबा है, जिसकी कमेंट्री बेहद बचकाने तरीके से की गई है। निर्देशक के रूप में रामगोपाल वर्मा ने दक्षिण भारतीय दर्शकों को ध्यान में रखकर वैसा ही टच दिया है। हालाँकि उन्होंने एक साधारण कहानी को स्क्रीन पर इस तरीके से पेश किया है बोरियत नहीं होती है। लेकिन उनसे भी ज्यादा काम किया है एक्शन डायरेक्टर एजाज-जावेद ने।\\n\\nरामू की फिल्म का बैकग्राउंड म्यूजिक अब दोहराव का शिकार हो गया है। \\u200d’रक्तचरित्र’ में भी बैकग्राउंड में श्लोक सुनाई देते हैं। सुखविंदर सिंह पर फिल्माया गया गीत ठूँसा हुआ लगता है।\\n\\nविवेक ओबेरॉय ने अभिनय के नाम पर सिर्फ बंदूक चलाई है। उन पर अभिमन्यु सिंह भारी पड़े हैं जिन्होंने बुक्का रेड्डी का रोल किया है। उन्हें फुटेज भी ज्यादा मिला है। आशीष विद्यार्थी, ज़रीना वहाब, दर्शन जरीवाला, शत्रुघ्न सिन्हा सहित सारे कलाकारों का अभिनय बेहतरीन है।\\n\\nकुल मिलाकर ‘रक्त चरित्र’ उन लोगों को पसंद आ सकती है, जो सिर्फ एक्शन पसंद करते हैं।',\n",
       "  '’उड़ान’ से विक्रमादित्य\\nमोटवाने\\nने अच्छे सिनेमा की उम्मीद जगाई थी और ‘लुटेरा’ में उन्होंने उम्मीदों को पूरा किया। एक बेहतरीन प्रेम कहानी लंबे समय बाद परदे पर आई है। ओ हेनरी की कहानी ‘द लास्ट लीफ’ को आधार बनाकर उसे गुजरे जमाने का टच दिया और अपने शानदार प्रस्तुति के बल पर विक्रम ने \\u200d’लुटेरे’ को देखने लायक बनाया है।\\n\\nपूरी फिल्म में निर्देशक का दबदबा है। उन्होंने दूसरी चीजों को हावी नहीं होने दिया और अपनी पकड़ बनाए रखी है। कई बार कहानी हिचकोले खाती है, लेकिन विक्रमादित्य ने इन झटकों को भी अच्छी तरह संभाल लिया है।\\n\\nकहानी पचास के दशक में सेट है। माणिकपुर का जमींदार उदास है। वह एक आम आदमी से कहता है कि आजादी तुम्हारे लिए खुशियां लाई हैं, लेकिन हमारी जिंदगी खराब हो गई है। सरकार ने जमींदारों से जमीन और कीमती सामान लेना शुरू कर दिए हैं। उनके दबदबे को खत्म किया जा रहा है। इस बात का फायदा कई लोग उठा रहे हैं और सरकारी ऑफिसर बन जमींदारों के माल पर हाथ साफ कर रहे हैं।\\nमनिकपुर में पुरातन विभाग का अधिकारी वरुण श्रीवास्तव आता है। जमींदार के मंदिर के आसपास खुदाई की इजाजत लेता है। उसका कहना है कि यहां कोई सभ्यता दफन है। युवा वरुण से जमींदार बाबू प्रभावित हो जाते हैं। भरोसा करते हुए इजाजत भी देते हैं।\\n\\nजमींदार बाबू की जान अपनी बेटी पाखी में रहती है। वरुण का जादू पाखी पर भी चल जाता है। पेंटिंग सीखने-सीखाने के बहाने दोनों का मेल-जोल बढ़ता है और वे करीब आ जाते हैं। लेकिन वरूण का असली चेहरा और नाम वो नहीं है जो पाखी और जमींदार बाबू समझ रहे थे। यही पर एक ट्विस्ट आता है। पाखी और जमींदार बाबू के होश उड़ जाते हैं।\\n\\n‘लुटेरा’ एक धीमी गति की फिल्म है। उसमें एक किस्म का ठहराव है। शुरुआत के कुछ मिनट सुस्ती भरे लगते हैं, लेकिन जैसे ही आप फिल्म की गति से तालमेल बिठाते हैं, फिल्म अच्छीम लगने लगती है।\\n\\nफिल्म दूसरे हाफ में डलहौजी में शिफ्ट होती है, यहां पर जरूर थोड़ी लंबी प्रतीत होती है, लेकिन एक शानदार क्लाइमेक्स के जरिये इसे संभाल लिया गया है। दूसरे हाफ में सोनाक्षी सिन्हा का रोल बहुत महत्वपूर्ण हो जाता है।\\n\\nवह वरुण से इतना प्रेम करती है कि अपने साथ किए गए धोखे और इससे पिता की हुई मौत के बावजूद उसे पुलिस के सुपुर्द नहीं करती है। वह समझ नहीं पाती कि वह ऐसा क्यों कर रही है। दरअसल वह प्रेम में इतनी ऊंचाई तक पहुंच जाती है कि हर अपराध के लिए अपने प्रेमी को क्षमा कर देती है।\\n\\nविक्रमादित्य ने ‘लुटेरा’ में पचास के दशक के माहौल को \\u200dबहुत ही खूबी के साथ पेश किया है। समय जैसा ठहरा हुआ लगता है। उस दौर के सुकून को महसूस किया जा सकता है। इसके लिए बंगाल से बेहतरीन जगह नहीं हो सकती थी। लंबी-चौड़ी\\u200d हवेली जमींदार के ठाठ-बाट को अच्छी तरह से पेश करती है।\\n\\nजहां तक खामियों का सवाल है तो एक चीज अखरती है। पाखी को जब पता चल जाता है कि वरुण को गोली लगी है तो एक बार \\u200dभी वह उससे इस बारे में बात नहीं करती। फिल्म में एक जगह देव आनंद पर कमेंट किया गया है कि वे फिल्म में गुंडों से फाइट करते थे, लेकिन उनका जमे बाल कभी नहीं बिखरते थे। ऐसी ही एक गलती विक्रमादित्य ने भी की है। डलहौजी की संकरी गलियों में एक लंबा चेज सीन फिल्माया गया है। गोलियां चलती है, लेकिन एक इंसान भी खिड़की खोलकर यह नहीं देखता कि बाहर क्या हो रहा है। एक सीन में नए जमाने की माचिस भी नजर आती है। कई बार संवाद किरदार के साथ न्याय नहीं कर पाते। लेकिन ये छोटी-मोटी बातें हैं और इससे फिल्म या कहानी पर ज्यादा असर नहीं होता।\\n\\nसोनाक्षी सिन्हा और \\u200dरणवीर सिंह जैसे कलाकारों को लेकर विक्रमादित्य ने जोखिम उठाया है। दोनों ने अब तक ऐसी फिल्म नहीं दी है, जिसको उनके \\u200dअभिनय के लिए याद किया जाए। अब दोनों कह सकते हैं कि ‘लुटेरा’ उनके करियर की बेहतरीन फिल्म है। नि:संदेह ये दोनों के करियर का अब तक सबसे अच्छा काम है, लेकिन इसके बावजूद दोनों की सीमा नजर आती है। यदि दोनों की जगह और बेहतरीन कलाकार होते तो फिल्म का प्रभाव और गहरा हो जाता है।\\n\\nजमींदार के रूप में बरुण चंद्रा ने कमाल का अभिनय किया है। अपनी बुलंद आवाज और शख्सियत के कारण वे रौबदार नजर आते हैं। उन्होंने उस जमींदार की भूमिका बेहतरीन तरीके से जिया है जो यह विश्वास ही नहीं कर पाता कि अब उसका समय जा चुका है। रणवीर के दोस्त के रूप में विक्रम मेसै ने भी अच्छा काम किया है।\\nसंगीत फिल्म का प्लस पाइंट है। संगीतकार अमित त्रिवेदी ने क्वांटिटी के बावजूद क्वालिटी मेंटेन कर रखी है। ‘संवार लूं’ तो हिट हो ही चुका है। अनकही, शिकायतें भी सुनने लायक हैं। क्लाइमेक्स में ‘जिंदा’ का बेहतरीन प्रयोग है। अमिताभ भट्टाचार्य ने उम्दा गीत लिखे हैं।\\n\\nफिल्म का बैकग्राउंड म्युजिक भी जबरदस्त है और इसका विक्रमादित्य ने बहुत अच्छे तरीके से इस्तेमाल किया है। कई दृश्य बिना बैकग्राउंड म्युजिक के कारण प्रभावी बने हैं। महेंद्र शेट्टी की सिनेमाटोग्राफी उन्हें कई अवॉर्ड्स दिला सकती है। कलाकारों के मूड और प्राकृतिक सौंदर्य को उन्होंने बखूबी कैद किया।\\n\\n‘लुटेरा’ शानदार प्रस्तुतिकरण के कारण देखी जानी चाहिए, बस ये थोड़ा धैर्य मांगती है।\\n\\nबैनर :\\nबालाजी मोशन पिक्चर्स, फैंटम प्रोडक्शन्स\\n\\nनिर्माता :\\nएकता कपूर, शोभा कपूर, अनुराग कश्यप, विकास बहल, मधु मटेंना, विक्रमादित्य\\nमोटवाने\\n\\nनिर्देशक :\\nविक्रमादित्य मोटव\\nान\\nे\\n\\nसंगीत :\\nअमित त्रिवेदी\\n\\nकलाकार :\\nरणवीर सिंह, सोनाक्षी सिन्हा, बरुण चंद्रा, विक्रम मेसै, आदिल हुसैन, आरिफ जकारिया\\n\\nसेंसर सर्टिफिकेट : यूए * 2 घंटे 22 मिनट 44 सेकंड',\n",
       "  'फिल्म में गानों के दृश्य में अनुष्का को माइक के सामने लक-दक कॉस्ट़्यूम में खड़े होकर गीतों के भाव को चेहरे पर लाना था।',\n",
       "  'फांसी चढ़ने से पहले वह पाकिस्तान के सदर से खास इजाजत लेकर मीडिया से मुखातिब होती है',\n",
       "  'राज कुमार हिरानी ने इस मूवी में भी अपने डायरेक्शन का जलवा दिखा दिया। उन्होंने साबित कर दिया कि उनके पिटारे से हर बार कुछ अलग और नया निकलता है। कहानी पर हिरानी की शुरू से आखिर तक पकड़ है। आमिर के रहते शरमन , माधवन , बोमन से हिरानी ने बेहतरीन काम लिया और हर एक की मौजूदगी को फिल्म का अहम हिस्सा बनाया। एक पल भी कहानी की गति को उन्होंने सुस्त नहीं पड़ने दिया।']}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ae60094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b3f49e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([32]),\n",
       " 'input_ids': torch.Size([32, 128, 50]),\n",
       " 'token_type_ids': torch.Size([32, 128]),\n",
       " 'attention_mask': torch.Size([32, 128])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f39d52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1356) torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09c186ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_fun = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_result = metric_fun.compute(references=labels, predictions=predictions)\n",
    "    return {\n",
    "        \"accuracy\": metric_result[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8cb53020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disable weights and biases logging\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "324b2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/bert-unigram-hindi-classifier\",\n",
    "    report_to = None,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    #learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    #weight_decay=0.02,\n",
    "    #warmup_ratio = 0.1,\n",
    "    #warmup_ratio = 0.05,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    #num_train_epochs=4,\n",
    "    #push_to_hub=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9d94821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# entire_train = concatenate_datasets([tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8085d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #train_dataset=entire_train,\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02236ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "trainer.remove_callback(transformers.integrations.TensorBoardCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20934010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1174615621566772,\n",
       " 'eval_accuracy': 0.2967741935483871,\n",
       " 'eval_runtime': 1.7944,\n",
       " 'eval_samples_per_second': 172.759,\n",
       " 'eval_steps_per_second': 5.573}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7440206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2480\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.904541</td>\n",
       "      <td>0.574194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.879726</td>\n",
       "      <td>0.603226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.918556</td>\n",
       "      <td>0.596774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=234, training_loss=0.7803325816097423, metrics={'train_runtime': 86.7317, 'train_samples_per_second': 85.782, 'train_steps_per_second': 2.698, 'total_flos': 2.977275585024e+16, 'train_loss': 0.7803325816097423, 'epoch': 3.0})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f026e2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8434534072875977,\n",
       " 'eval_accuracy': 0.6387096774193548,\n",
       " 'eval_runtime': 1.6966,\n",
       " 'eval_samples_per_second': 182.717,\n",
       " 'eval_steps_per_second': 5.894,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "036d1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d323c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"models/bert-unigram-hindi-classifier\")\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddefcfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.918556272983551,\n",
       " 'eval_accuracy': 0.5967741935483871,\n",
       " 'eval_runtime': 1.7961,\n",
       " 'eval_samples_per_second': 172.596,\n",
       " 'eval_steps_per_second': 5.568,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
